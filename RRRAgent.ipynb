{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.14)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "import torch.nn.functional as F\n",
    "import minigrid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from tqdm.notebook import tqdm\n",
    "from minigrid.envs.doorkey import DoorKeyEnv\n",
    "import pandas as pd\n",
    "from gym.envs.registration import registry, register\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing_extensions import Self\n",
    "import matplotlib.pyplot as plt\n",
    "from minigrid.wrappers import ObservationWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Returns the device to use for training.\n",
    "    \"\"\"\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr/blob/master/model.py\n",
    "def init_params(m):\n",
    "    \"\"\"\n",
    "    Initialize parameters of the network.\n",
    "    m: torch.nn.Module\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Linear\") != -1:\n",
    "        m.weight.data.normal_(0, 1)\n",
    "        m.weight.data *= 1 / torch.sqrt(m.weight.data.pow(2).sum(1, keepdim=True))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "class MyDoorKeyEnv(DoorKeyEnv):\n",
    "    def __init__(self, size):\n",
    "        self.render_mode = \"rgb_array\"\n",
    "        super().__init__(size=size)\n",
    "\n",
    "    def _reward(self):\n",
    "        \"\"\"\n",
    "        Compute the reward to be given upon success\n",
    "        \"\"\"\n",
    "        return 1\n",
    "\n",
    "class ImgObsWrapper(ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Use the image as the only observation output, no language/mission.\n",
    "\n",
    "    Parameters:\n",
    "    - env (gym.Env): The environment to wrap.\n",
    "\n",
    "    Methods:\n",
    "    - observation(self, obs): Returns the image from the observation.\n",
    "    - reset(self): Resets the environment and returns the initial observation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        Initializes the ImgObsWrapper with the given environment.\n",
    "\n",
    "        Parameters:\n",
    "        - env (gym.Env): The environment whose observations are to be wrapped.\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self.observation_space = env.observation_space.spaces[\"image\"]\n",
    "\n",
    "    def observation(self, obs):\n",
    "        \"\"\"\n",
    "        Extracts and returns the image data from the observation.\n",
    "\n",
    "        Parameters:\n",
    "        - obs (dict or tuple): The original observation from the environment, which could be either\n",
    "        a dictionary or a tuple containing a dictionary.\n",
    "\n",
    "        Returns:\n",
    "        - np.ndarray: The image data extracted from the observation.\n",
    "        \"\"\"\n",
    "        if type(obs) == tuple:\n",
    "            return obs[0][\"image\"]\n",
    "        return obs[\"image\"]\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment and returns the initial observation image.\n",
    "\n",
    "        Returns:\n",
    "        - np.ndarray: The initial observation image of the reset environment.\n",
    "        \"\"\"\n",
    "        obs = super().reset()\n",
    "        return obs[0]\n",
    "    \n",
    "def get_door_key_env(size):\n",
    "    \"\"\"\n",
    "    Returns a DoorKeyEnv environment with the given size.\n",
    "    \"\"\"\n",
    "    env = MyDoorKeyEnv(size=size)\n",
    "    env = ImgObsWrapper(env)\n",
    "\n",
    "    env.reset()\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # get an RGB image corresponding to the whole environment or the agent's point of view (https://github.com/Farama-Foundation/Minigrid/blob/master/minigrid/minigrid_env.py#L716)\n",
    "    #            highlight (bool): If true, the agent's field of view or point of view is highlighted with a lighter gray color.\n",
    "    #            tile_size (int): How many pixels will form a tile from the NxM grid.\n",
    "    #            agent_pov (bool): If true, the rendered frame will only contain the point of view of the agent.\n",
    "    frame = env.get_frame(highlight=env.highlight, tile_size=env.tile_size, agent_pov=env.agent_pov)\n",
    "    # show an image to the notebook.\n",
    "    plt.imshow(frame)\n",
    "\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Stores algorithmic hyperparameters.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                score_threshold=0.93,\n",
    "                discount=0.995,\n",
    "                lr=1e-3,\n",
    "                max_grad_norm=0.5,\n",
    "                log_interval=10,\n",
    "                gae_lambda=0.95,\n",
    "                clip_ratio=0.2,\n",
    "                target_kl=0.01,\n",
    "                train_ac_iters=5,\n",
    "                use_discounted_reward=True,\n",
    "                use_gae=True,\n",
    "                importance_sampling_clip=2.0,\n",
    "                bad_fit_threshold=0.8,\n",
    "                bad_fit_increment=None,\n",
    "                replay_buffer_capacity=10,\n",
    "                large_buffer_capacity=20):\n",
    "\n",
    "        self.score_threshold = score_threshold # criterion for early stopping. If the rolling average reward (over the last 100 episodes) is greater than it, it ends.\n",
    "        self.discount = discount # discount factor\n",
    "        self.lr = lr # learning rate\n",
    "        self.max_grad_norm = max_grad_norm # the maximum gradient norm (https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
    "        self.log_interval = log_interval # logging interval\n",
    "        self.clip_ratio = clip_ratio # clip_ratio of PPO.\n",
    "        self.target_kl = target_kl # target KL divergence for early stoping train_ac_iters for PPO\n",
    "        self.train_ac_iters = train_ac_iters # how many time to train ac_model using current computed old_logps\n",
    "        self.gae_lambda=gae_lambda # lambda in Generalized Advantage Estimation (GAE)\n",
    "        self.use_discounted_reward=use_discounted_reward # whether use discounted reward or not.\n",
    "        self.use_gae = use_gae # whether to use GAE or not.\n",
    "        self.importance_sampling_clip = importance_sampling_clip # importance sampling clip threshold\n",
    "        self.bad_fit_threshold = bad_fit_threshold # threshold for bad fit.\n",
    "        if bad_fit_increment is None:\n",
    "            bad_fit_increment = (1.0 - bad_fit_threshold) / replay_buffer_capacity\n",
    "        self.bad_fit_increment = bad_fit_increment # increment for bad fit.\n",
    "        self.replay_buffer_capacity = replay_buffer_capacity # capacity of replay buffer.\n",
    "        self.large_buffer_capacity = large_buffer_capacity # capacity of large replay buffer.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "    def __init__(self, entropy_coef, init_model:nn.Module, args:Config=None):\n",
    "        \"\"\"\n",
    "        A Machine object consists of a Model and its entropy_coef\n",
    "\n",
    "        Args:\n",
    "            entropy_coef: Entropy coefficient.\n",
    "            init_model: Initial model.\n",
    "            args\n",
    "        \"\"\"\n",
    "        if args is None:\n",
    "            self.args = Config()\n",
    "        else:\n",
    "            self.args = args\n",
    "\n",
    "        self.model = init_model\n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.args.lr)\n",
    "        self.coef = entropy_coef\n",
    "        self.device = get_device()\n",
    "\n",
    "    def copy_model(self, other_model:nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Copy state dict from 'model'. Reset rs.\n",
    "        \"\"\"\n",
    "        state_dict = other_model.state_dict()\n",
    "        for key, v in state_dict.items():\n",
    "            if key in self.model.state_dict():\n",
    "                self.model.state_dict()[key].copy_(v)\n",
    "\n",
    "    def copy_machine(self, other:Self) -> None:\n",
    "        \"\"\"\n",
    "        Copy state dict from 'other'. Reset rs.\n",
    "        \"\"\"\n",
    "        self.copy_model(other.model)\n",
    "\n",
    "    def _compute_discounted_return(self, rewards):\n",
    "        \"\"\"\n",
    "            rewards: reward obtained at timestep.  Shape: (T,)\n",
    "            discount: discount factor. float\n",
    "\n",
    "        ----\n",
    "        returns: sum of discounted rewards. Shape: (T,)\n",
    "        \"\"\"\n",
    "        returns = torch.zeros(*rewards.shape, device=self.device)\n",
    "\n",
    "        R = 0\n",
    "        for t in reversed(range((rewards.shape[0]))):\n",
    "            R = rewards[t] + self.args.discount * R\n",
    "            returns[t] = R\n",
    "        return returns\n",
    "\n",
    "    def _compute_advantage_gae(self, values, rewards, T):\n",
    "        \"\"\"\n",
    "        Compute Adavantage wiht GAE. See Section 4.4.2 in the lecture notes.\n",
    "\n",
    "        values: value at each timestep (T,)\n",
    "        rewards: reward obtained at each timestep.  Shape: (T,)\n",
    "        T: the number of frames, float\n",
    "        gae_lambda: hyperparameter, float\n",
    "        discount: discount factor, float\n",
    "\n",
    "        -----\n",
    "\n",
    "        returns:\n",
    "\n",
    "        advantages : tensor.float. Shape [T,]\n",
    "\n",
    "                    gae advantage term for timesteps 0 to T\n",
    "\n",
    "        \"\"\"\n",
    "        advantages = torch.zeros_like(values)\n",
    "        for i in reversed(range(T)):\n",
    "            next_value = values[i+1]\n",
    "            next_advantage = advantages[i+1]\n",
    "\n",
    "            delta = rewards[i] + self.args.discount * next_value  - values[i]\n",
    "            advantages[i] = delta + self.args.discount * self.args.gae_lambda * next_advantage\n",
    "        return advantages[:T]\n",
    "    \n",
    "    def collect_experiences(self, env:gym.Env):\n",
    "        \"\"\"\n",
    "        Collects rollouts and computes advantages.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        exps : dict\n",
    "            Contains actions, rewards, advantages etc as attributes.\n",
    "            Each attribute, e.g. `exps['reward']` has a shape\n",
    "            (self.num_frames, ...).\n",
    "        logs : dict\n",
    "            Useful stats about the training process, including the average\n",
    "            reward, policy loss, value loss, etc.\n",
    "        \"\"\"\n",
    "        device = get_device()\n",
    "\n",
    "        MAX_FRAMES_PER_EP = 300\n",
    "        shape = (MAX_FRAMES_PER_EP, )\n",
    "\n",
    "        actions = torch.zeros(*shape, device=device, dtype=torch.int)\n",
    "        values = torch.zeros(*shape, device=device)\n",
    "        rewards = torch.zeros(*shape, device=device)\n",
    "        log_probs = torch.zeros(*shape, device=device)\n",
    "        obss = [None]*MAX_FRAMES_PER_EP\n",
    "\n",
    "        obs = env.reset()\n",
    "\n",
    "        total_return = 0\n",
    "\n",
    "        T = 0\n",
    "\n",
    "        while True:\n",
    "            # Do one agent-environment interaction\n",
    "            with torch.no_grad():\n",
    "                dist, value = self.model(obs)\n",
    "\n",
    "            dist: Categorical\n",
    "            action = dist.sample()[0]\n",
    "\n",
    "            obss[T] = obs\n",
    "            obs, reward, done, _, _ = env.step(action.item())\n",
    "\n",
    "            # Update experiences values\n",
    "            actions[T] = action\n",
    "            values[T] = value\n",
    "            rewards[T] = reward\n",
    "            log_probs[T] = dist.log_prob(action)\n",
    "\n",
    "            total_return += reward\n",
    "            T += 1\n",
    "\n",
    "            if done or T >= MAX_FRAMES_PER_EP-1:\n",
    "                break\n",
    "\n",
    "        success = (total_return > 0.5)\n",
    "        \n",
    "        discounted_reward = self._compute_discounted_return(rewards[:T])\n",
    "        exps = dict(\n",
    "            obs = torch.tensor(obss[:T], device=device),\n",
    "            action = actions[:T],\n",
    "            value  = values[:T],\n",
    "            reward = rewards[:T],\n",
    "            log_prob = log_probs[:T],\n",
    "            discounted_reward = discounted_reward,\n",
    "            T = T\n",
    "        )\n",
    "\n",
    "        logs = {\n",
    "            \"return_per_episode\": total_return,\n",
    "            \"num_frames\": T,\n",
    "            'success': success\n",
    "        }\n",
    "\n",
    "        return exps, logs\n",
    "\n",
    "    def _compute_policy_loss_ppo(self, dist:Categorical, factors, indices, old_logp, actions, advantages):\n",
    "        \"\"\"\n",
    "        Computes the policy loss for PPO.\n",
    "\n",
    "        obs: observeration to pass into acmodel. shape: (T,)\n",
    "        init_logp: log probabilities we get from the agent performing the action. shape: (T,)\n",
    "        old_logp: log probabilities from previous timestep. shape: (T,)\n",
    "        actions: action at this timestep. shape: (T,ImWidth,ImHeight,Channels)\n",
    "        advantages: the computed advantages. shape: (T,)\n",
    "\n",
    "        ---\n",
    "        returns\n",
    "\n",
    "        policy_loss : ppo policy loss as shown in line 6 of PPO alg. tensor.float. Shape (,1)\n",
    "        approx_kl: an appoximation of the kl_divergence. tensor.float. Shape (,1)\n",
    "        \"\"\"\n",
    "        policy_loss, approx_kl = 0, 0\n",
    "\n",
    "        coef = self.coef\n",
    "\n",
    "        entropy = dist.entropy()\n",
    "        logps = dist.log_prob(actions)\n",
    "        r_terms = torch.exp(logps - old_logp)\n",
    "        ppo_loss = torch.min(r_terms * advantages, torch.clamp(r_terms, 1 - self.args.clip_ratio, 1 + self.args.clip_ratio) * advantages)\n",
    "        \n",
    "        policy_loss_tensor = factors * ppo_loss + coef * entropy\n",
    "\n",
    "        policy_loss = - torch.mean(policy_loss_tensor[indices])\n",
    "\n",
    "        # approx_kl = torch.sum(torch.exp(old_logp) * (old_logp - logps)) / torch.sum(torch.exp(old_logp))\n",
    "        approx_kl = torch.mean((old_logp - logps) ** 2) / 2\n",
    "\n",
    "        return policy_loss, approx_kl\n",
    "    \n",
    "    def _compute_value_loss(self, values, returns):\n",
    "        value_loss = torch.mean((values - returns) ** 2)\n",
    "\n",
    "        return value_loss\n",
    "\n",
    "    def update_parameters(self, sb, update_v=True):\n",
    "        MAX_FRAMES_PER_EP = 300\n",
    "        T = sb['T']\n",
    "        with torch.no_grad():\n",
    "            dist, values = self.model(sb['obs'])\n",
    "        values = values.reshape(-1)\n",
    "        dist: Categorical\n",
    "        old_logp = dist.log_prob(sb['action'])\n",
    "        init_logp = sb['log_prob']\n",
    "\n",
    "        # add 0 to end of values until it has length MAX_FRAMES_PER_EP\n",
    "        values_extended = torch.cat([values, torch.zeros((MAX_FRAMES_PER_EP - len(values), ), device=get_device())], dim=0)\n",
    "        full_reward = torch.cat([sb['reward'], torch.zeros((MAX_FRAMES_PER_EP - len(sb['reward']), ), device=get_device())], dim=0)\n",
    "\n",
    "        if self.args.use_gae:\n",
    "            advantage = self._compute_advantage_gae(values_extended, full_reward, T)\n",
    "        else:\n",
    "            advantage = sb['discounted_reward'] - values.reshape(-1)\n",
    "\n",
    "        for i in range(self.args.train_ac_iters):\n",
    "            self.optim.zero_grad()\n",
    "            dist, values = self.model(sb['obs'])\n",
    "            values = values.reshape(-1)\n",
    "            # policy loss\n",
    "            factors = torch.exp(old_logp - init_logp)\n",
    "            indices = factors < self.args.importance_sampling_clip\n",
    "            fit = torch.mean(indices.to(torch.float32))\n",
    "\n",
    "            loss_pi, approx_kl = self._compute_policy_loss_ppo(dist, factors, indices, old_logp, sb['action'], advantage)\n",
    "            if update_v:\n",
    "                loss_v = self._compute_value_loss(values, sb['discounted_reward'])\n",
    "            else:\n",
    "                loss_v = 0.0\n",
    "\n",
    "            if i == 0:\n",
    "                policy_loss = loss_pi\n",
    "                value_loss = loss_v\n",
    "\n",
    "            loss = loss_v + loss_pi\n",
    "            if approx_kl > 1.5 * self.args.target_kl:\n",
    "                break\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            self.optim.step()\n",
    "\n",
    "        update_policy_loss = policy_loss.item()\n",
    "        update_value_loss = value_loss.item()\n",
    "\n",
    "        logs = {\n",
    "            \"policy_loss\": update_policy_loss,\n",
    "            \"value_loss\": update_value_loss,\n",
    "            \"fit\": fit.item()\n",
    "        }\n",
    "\n",
    "        return logs\n",
    "    \n",
    "    def decrease_prob(self, sb, lr=0.1) -> None:\n",
    "        self.optim.zero_grad()\n",
    "\n",
    "        dist, _ = self.model(sb['obs'])\n",
    "        dist: Categorical\n",
    "        logps = dist.log_prob(sb['action'])\n",
    "\n",
    "        loss = lr * torch.mean(logps)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def __init__(self, ACModelClass, env, args:Config=None, seed=0):\n",
    "        \"\"\"\n",
    "        The PPO agent.\n",
    "        \"\"\"\n",
    "\n",
    "        self.env = env\n",
    "\n",
    "        set_random_seed(seed)\n",
    "        model = ACModelClass(use_critic=True)\n",
    "\n",
    "        if args is None:\n",
    "            args = Config()\n",
    "        self.machine = Machine(0.01, model, args)\n",
    "    \n",
    "    def train(self, max_episodes:int=10000, nonstop:bool=False) -> tuple[list[int], list[float]]:\n",
    "        \"\"\"\n",
    "        Train the PPO agent.\n",
    "\n",
    "        Returns:\n",
    "            num_frames, smooth_rs\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f'Start! Agent: PPO.')\n",
    "\n",
    "        is_solved = False\n",
    "\n",
    "        SMOOTH_REWARD_WINDOW = 50\n",
    "\n",
    "        rewards = [0]*SMOOTH_REWARD_WINDOW\n",
    "\n",
    "        total_smooth_rs = []\n",
    "        total_num_frames = []\n",
    "\n",
    "        num_frames = 0\n",
    "\n",
    "        pbar = tqdm(range(max_episodes))\n",
    "        for update in pbar:\n",
    "\n",
    "            exps, logs1 = self.machine.collect_experiences(self.env)\n",
    "\n",
    "            logs2 = self.machine.update_parameters(exps)\n",
    "\n",
    "            logs = {**logs1, **logs2}\n",
    "\n",
    "            total_num_frames.append(num_frames)\n",
    "            num_frames += logs[\"num_frames\"]\n",
    "\n",
    "            rewards.append(logs[\"return_per_episode\"])\n",
    "\n",
    "            smooth_reward = np.mean(rewards[-SMOOTH_REWARD_WINDOW:])\n",
    "\n",
    "            total_smooth_rs.append(smooth_reward)\n",
    "\n",
    "            data = {'num_frames':num_frames, 'smooth_reward':smooth_reward,\n",
    "                'reward':logs[\"return_per_episode\"], 'policy_loss':logs[\"policy_loss\"], 'value_loss': logs['value_loss'], 'episode':update}\n",
    "\n",
    "            pbar.set_postfix(data)\n",
    "\n",
    "            if not nonstop and smooth_reward >= self.machine.args.score_threshold:\n",
    "                is_solved = True\n",
    "                break\n",
    "\n",
    "        if not nonstop and is_solved:\n",
    "            print('Solved!')\n",
    "\n",
    "        return total_num_frames, total_smooth_rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class DQNetwork(nn.Module):\n",
    "    def __init__(self, action_dim):\n",
    "        \"\"\"\n",
    "        Initializes the DQNetwork with a convolutional neural network architecture.\n",
    "\n",
    "        Parameters:\n",
    "        - action_dim (int): The number of possible actions, determining the output size of the network.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (3, 3)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, action_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, ob):\n",
    "        \"\"\"\n",
    "        Processes an observation through the network to predict Q values for each action.\n",
    "\n",
    "        Parameters:\n",
    "        - ob (torch.Tensor): The input observation image of shape [batch_size, height, width, channels].\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: The predicted Q values for each action, of shape [batch_size, action_dim].\n",
    "        \"\"\"\n",
    "        #### TODO (5pts): get the Q values for each action given the input\n",
    "        #### the input shape is: [batch_size, H, W, 3]\n",
    "        #### output shape should be: [batch_size, # of actions]\n",
    "        ob = ob.permute(0, 3, 1, 2)\n",
    "        bs = ob.size(0)\n",
    "        out = self.conv_net(ob)\n",
    "        out = out.view(bs, -1)\n",
    "        out = self.fcs(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# create a replay buffer\n",
    "class CyclicBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = []\n",
    "        self.capacity = capacity\n",
    "        self.cur_pos = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.buffer[item]\n",
    "\n",
    "    def append(self, data):\n",
    "        \"\"\"\n",
    "        Adds a new piece of data to the buffer.\n",
    "\n",
    "        Parameters:\n",
    "        - data: The data to be added to the buffer.\n",
    "        \"\"\"\n",
    "        #### TODO (10pts): add data to the buffer\n",
    "        #### if the buffer is not full yet, you can simply append the data to the buffer\n",
    "        #### otherwise, you need to replace the oldest data with the current data (FIFO)\n",
    "        #### Hint: you may find self.cur_pos useful, it can be used as a position index\n",
    "        #### to keep track of where to add data\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(data)\n",
    "            self.cur_pos = (self.cur_pos + 1) % self.capacity\n",
    "        else:\n",
    "            self.buffer[self.cur_pos] = data\n",
    "            self.cur_pos = (self.cur_pos + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Randomly selects a batch of data from the buffer. The size of the batch is the minimum of the requested\n",
    "        batch size and the current size of the buffer. If the requested batch size equals the buffer size, all\n",
    "        data in the buffer is returned.\n",
    "\n",
    "        Parameters:\n",
    "        - batch_size (int): The size of the batch to sample.\n",
    "\n",
    "        Returns:\n",
    "        - list: A list containing the sampled batch of data.\n",
    "        \"\"\"\n",
    "        #### TODO (10pts): sample a batch from the buffer\n",
    "        bs = min(batch_size, len(self.buffer))\n",
    "        return random.sample(self.buffer, bs)\n",
    "\n",
    "    def get_all(self):\n",
    "        \"\"\"\n",
    "        Retrieves all data stored in the buffer.\n",
    "\n",
    "        Returns:\n",
    "        - list: A deepcopy of all data currently stored in the buffer.\n",
    "        \"\"\"\n",
    "        return deepcopy(self.buffer)\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"\n",
    "        Removes all data from the buffer, effectively resetting its state.\n",
    "        \"\"\"\n",
    "        self.buffer.clear()\n",
    "        self.cur_pos = 0\n",
    "\n",
    "@dataclass\n",
    "class DQNAgent:\n",
    "    env: gym.Env\n",
    "    learning_rate: float\n",
    "    gamma: float\n",
    "    memory_size: int # We use memory/buffer interchangeably\n",
    "    initial_epsilon: float\n",
    "    min_epsilon: float\n",
    "    max_epsilon_decay_steps: int\n",
    "    warmup_steps: int\n",
    "    batch_size: int\n",
    "    target_update_freq: int\n",
    "    enable_double_q: bool = False\n",
    "    disable_target_net: bool = False\n",
    "    device: str = None\n",
    "    tau: float = 0.005\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the agent to its initial state.\n",
    "        \"\"\"\n",
    "        if self.device is None:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        #### TODO: create a Deep Q network Agent.\n",
    "        #### For our purposes include the following:\n",
    "        #### -a replay buffer with capacity=self.memory_size. Memory = Buffer\n",
    "        self.memory = CyclicBuffer(self.memory_size)\n",
    "        #### -an Adam optimizer with lr=self.learning_rate,\n",
    "        self.qnet = DQNetwork(action_dim=7).to(self.device)\n",
    "        self.optim = torch.optim.Adam(self.qnet.parameters(), lr=self.learning_rate)\n",
    "        #### -SmoothL1 loss instance,\n",
    "        self.loss = nn.SmoothL1Loss()\n",
    "        ####  -a deep Q network\n",
    "        ####  -A deep Q TARGET network (Make sure to set to eval mode)\n",
    "        self.target_qnet = DQNetwork(action_dim=7).to(self.device)\n",
    "        self.target_qnet.eval()\n",
    "        #### -Make sure the networks are on the correct device!!! use [tensor].to(self.device)\n",
    "\n",
    "        ####\n",
    "        self.epsilon = self.initial_epsilon\n",
    "        self.ep_reduction = (self.epsilon - self.min_epsilon) / float(self.max_epsilon_decay_steps)\n",
    "        if self.disable_target_net:\n",
    "            #### TODO: set the target_update_freq to be proper value so that the target Q network will always be same as the Q network\n",
    "            #### You don't need to fill in this value until Q4.3\n",
    "            self.target_update_freq = 1\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_action(self, ob, greedy_only=False):\n",
    "        \"\"\"\n",
    "        Selects an action based on the current state observation using an epsilon-greedy policy.\n",
    "\n",
    "        Parameters:\n",
    "        - ob (numpy.ndarray): The current state observation.\n",
    "        - greedy_only (bool): If True, the method always selects the action with the highest Q value. If False, it\n",
    "        selects a random action with probability epsilon.\n",
    "\n",
    "        Returns:\n",
    "        - int: The selected action.\n",
    "        \"\"\"\n",
    "        ob = ob[np.newaxis, :]\n",
    "        ob = torch.from_numpy(ob).float().to(self.device)\n",
    "        q_val = self.qnet(ob)\n",
    "        action = self.epsilon_greedy_policy(q_val, greedy_only=greedy_only)\n",
    "        return action\n",
    "\n",
    "    def epsilon_greedy_policy(self, q_values, greedy_only=False):\n",
    "        \"\"\"\n",
    "        Implements an epsilon-greedy policy for action selection.\n",
    "\n",
    "        Parameters:\n",
    "        - q_values (torch.Tensor): The Q values for all actions in the current state.\n",
    "        - greedy_only (bool): If True, ignores epsilon and selects the action with the highest Q value.\n",
    "\n",
    "        Returns:\n",
    "        - int: The index of the selected action.\n",
    "        \"\"\"\n",
    "        #### TODO: epsilon greedy exploration\n",
    "        #### we have an extra flag `greedy_only` here,\n",
    "        #### if greedy_only is True, then we need to return the action that\n",
    "        #### has the maximum Q values.\n",
    "        #### if greedy_only is False, we do epsilon greedy.\n",
    "        mode = 'random'\n",
    "        if greedy_only:\n",
    "            mode = 'greedy'\n",
    "        else:\n",
    "            if random.random() < self.epsilon:\n",
    "                mode = 'random'\n",
    "            else:\n",
    "                mode = 'greedy'\n",
    "\n",
    "        if mode == 'random':\n",
    "            action = np.random.randint(0, 7)\n",
    "        elif mode == 'greedy':\n",
    "            action = torch.argmax(q_values).item()\n",
    "        else:\n",
    "            raise ValueError('Unknown mode')\n",
    "\n",
    "        return action\n",
    "\n",
    "    def add_to_memory(self, ob, next_ob, action, reward, done):\n",
    "        \"\"\"\n",
    "        Adds an experience tuple to the replay buffer.\n",
    "\n",
    "        Parameters:\n",
    "        - ob: The current state observation.\n",
    "        - next_ob: The next state observation after taking the action.\n",
    "        - action: The action taken in the current state.\n",
    "        - reward: The reward received after taking the action.\n",
    "        - done: A boolean indicating whether the episode has ended.\n",
    "        \"\"\"\n",
    "        #### TODO: add data to the replay buffer. Avoid np.arrays.\n",
    "        data = (ob, next_ob, action, reward, done)\n",
    "        self.memory.append(data)\n",
    "\n",
    "    def update_Q(self):\n",
    "        \"\"\"\n",
    "        Performs a single update step of the Q-network based on a batch of experiences from the replay buffer.\n",
    "\n",
    "        Returns:\n",
    "        - float: The loss value of the update step.\n",
    "        \"\"\"\n",
    "        # we only start updating the Q network if there are enough samples in the replay buffer\n",
    "        if len(self.memory) < self.warmup_steps:\n",
    "            return 0\n",
    "\n",
    "        #### TODO: sample data from the replay buffer, and put them on the correct device (use [tensor].to(self.device))\n",
    "        #### you need to make sure the variables are in the right tensor shape.\n",
    "        data = self.memory.sample(self.batch_size)\n",
    "\n",
    "\n",
    "        #### TODO: update Q function with Bellman backup. Torch.gather() may prove useful for this section\n",
    "        ##### get Q(s_t, a_t)\n",
    "        obs, next_obs, actions, rewards, dones = zip(*data)\n",
    "        obs = torch.tensor(obs, device=self.device, dtype=torch.float32)\n",
    "        next_obs = torch.tensor(next_obs, device=self.device, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, device=self.device)\n",
    "        rewards = torch.tensor(rewards, device=self.device, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, device=self.device, dtype=torch.int32)\n",
    "\n",
    "        q_values = self.qnet(obs)\n",
    "        # then select the index from q_values according to actions\n",
    "        q_values = q_values.gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "\n",
    "        ##### get maxQ(s_{t+1}, a_{t+1})\n",
    "        ##### you will need to implement both DQN and double DQN here\n",
    "        ##### i.e., you need to check `if self.enable_double_q`\n",
    "        ##### remember to not propogate gradient when working with target\n",
    "        if self.enable_double_q:\n",
    "            with torch.no_grad():\n",
    "                out = self.qnet(next_obs)\n",
    "                max_q_indices = torch.max(out, dim=1)[1]\n",
    "\n",
    "                out = self.target_qnet(next_obs)\n",
    "                max_q_values = out.gather(1, max_q_indices.unsqueeze(1)).squeeze(1)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                out = self.target_qnet(next_obs)\n",
    "                max_q_values = torch.max(out, dim=1)[0]\n",
    "\n",
    "\n",
    "        ##### get the target Q value from the bellman equation\n",
    "        target_q_values = rewards + (1 - dones) * self.gamma * max_q_values\n",
    "\n",
    "        ##### update the Q network\n",
    "        self.optim.zero_grad()\n",
    "        loss = self.loss(target_q_values, q_values)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        \"\"\"\n",
    "        Reduces epsilon linearly over time until it reaches min_epsilon, ensuring that the exploration rate decreases\n",
    "        as the agent learns more about the environment.\n",
    "        \"\"\"\n",
    "        #### TODO: linearly decay epsilon\n",
    "        #### reduce epsilon value by ep_reduction every time the function is called,\n",
    "        #### make sure epsilon is not smaller than self.min_epsilon\n",
    "        self.epsilon = max(self.epsilon - self.ep_reduction, self.min_epsilon)\n",
    "\n",
    "    def set_epsilon(self, eps) -> None:\n",
    "        \"\"\"\n",
    "        Sets the epsilon value to a specified value.\n",
    "\n",
    "        Parameters:\n",
    "        - eps (float): The new epsilon value.\n",
    "        \"\"\"\n",
    "        self.epsilon = eps\n",
    "\n",
    "    def update_target_qnet(self, step, soft=True):\n",
    "        \"\"\"\n",
    "        Updates the target Q-network.\n",
    "\n",
    "        Parameters:\n",
    "        - step (int): The current step number, used to determine when to perform hard updates.\n",
    "        - soft (bool): If True, performs a soft update; otherwise, performs a hard update.\n",
    "        \"\"\"\n",
    "        if not soft:\n",
    "            if step % self.target_update_freq == 0:\n",
    "                #### TODO: update the target Q function in a \"hard\" way\n",
    "                #### copy the parameter values in self.qnet into self.target_qnet\n",
    "                ### use .copy_() to avoid pointer issues\n",
    "                state_dict = self.qnet.state_dict()\n",
    "                for key, v in state_dict.items():\n",
    "                    self.target_qnet.state_dict()[key].copy_(v)\n",
    "                self.target_qnet.eval()\n",
    "        else:\n",
    "            #### TODO: soft update on taget Q network.\n",
    "            #### similar to polyak averaging, we update the target Q network slowly\n",
    "            #### $\\theta_Qtgt = \\tau*\\theta_Qtgt + (1-\\tau)*\\theta_Q\n",
    "            ###  use .copy_() to avoid pointer issues\n",
    "            state_dict = self.qnet.state_dict()\n",
    "            for key, v in state_dict.items():\n",
    "                self.target_qnet.state_dict()[key].copy_((1 - self.tau) * self.target_qnet.state_dict()[key] + self.tau * v)\n",
    "            self.target_qnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRR:\n",
    "    def __init__(self, ACModelClass, env, args:Config=None, seed=0):\n",
    "        \"\"\"\n",
    "        The RRR agent.\n",
    "        \"\"\"\n",
    "\n",
    "        self.env = env\n",
    "\n",
    "        set_random_seed(seed)\n",
    "        m1 = ACModelClass(use_critic=True)\n",
    "\n",
    "        if args is None:\n",
    "            args = Config()\n",
    "\n",
    "        self.exploiter = Machine(0.01, m1, args)\n",
    "\n",
    "        m2 = ACModelClass(use_critic=False)\n",
    "        m3 = ACModelClass(use_critic=False)\n",
    "        m4 = ACModelClass(use_critic=False)\n",
    "\n",
    "        self.explorer_random = Machine(0.03, m2, args)\n",
    "        self.explorer_thirsty = Machine(0.02, m3, args)\n",
    "        self.explorer_thirsty.copy_machine(self.exploiter)\n",
    "\n",
    "        self.temp_machine = Machine(0.01, m3, args)\n",
    "        self.explorer_bengbuzhu = Machine(0.5, m4, args)\n",
    "\n",
    "    def _replay(self, machine:Machine, buffer:list, cutoff:float) -> float:\n",
    "        \"\"\"\n",
    "        Replay random sample from buffer on machine.\n",
    "\n",
    "        Args:\n",
    "            machine: Machine to replay on\n",
    "            buffer: list of experiences\n",
    "            cutoff: if fit < cutoff, delete sb from buffer\n",
    "\n",
    "        Returns:\n",
    "            fit\n",
    "        \"\"\"\n",
    "\n",
    "        idx = np.random.randint(len(buffer))\n",
    "        sb = buffer[idx]\n",
    "        logs_replay = machine.update_parameters(sb)\n",
    "        fit = logs_replay['fit']\n",
    "        if fit < cutoff:\n",
    "            # delete sb from buffer\n",
    "            buffer.pop(idx)\n",
    "        \n",
    "        return fit\n",
    "    \n",
    "    def _add_sb_to_buffer(self, exps, buffer:list, capacity:int) -> None:\n",
    "        buffer.append(exps)\n",
    "        if len(buffer) > capacity:\n",
    "            buffer.pop(0)\n",
    "\n",
    "\n",
    "    def train(self, max_episodes:int=10000, nonstop:bool=False) -> tuple[list[int], list[float], list[float]]:\n",
    "        \"\"\"\n",
    "        Train the agent.\n",
    "\n",
    "        Returns:\n",
    "            num_frames, smooth_rs, fits\n",
    "        \"\"\"\n",
    "\n",
    "        print('Start! Agent: RRR.')\n",
    "        RANDOM_MODE = 0\n",
    "        EXPLORE_MODE = 1\n",
    "        EXPLOIT_MODE = 2\n",
    "        mode = RANDOM_MODE\n",
    "\n",
    "        is_solved = False\n",
    "\n",
    "        SMOOTH_REWARD_WINDOW = 50\n",
    "\n",
    "        rewards = [0]*SMOOTH_REWARD_WINDOW\n",
    "\n",
    "        total_smooth_rs = []\n",
    "        total_num_frames = []\n",
    "        larger_buffer_r = []\n",
    "        buffer_r = []\n",
    "        buffer_no_r = []\n",
    "        fits = []\n",
    "\n",
    "        num_frames = 0\n",
    "\n",
    "        pbar = tqdm(range(max_episodes))\n",
    "        for update in pbar:\n",
    "            total_num_frames.append(num_frames)\n",
    "\n",
    "            if mode == RANDOM_MODE:\n",
    "                exps, logs1 = self.explorer_bengbuzhu.collect_experiences(self.env)\n",
    "                self.explorer_bengbuzhu.update_parameters(exps)\n",
    "                logs2 = self.exploiter.update_parameters(exps)\n",
    "            \n",
    "            elif mode == EXPLORE_MODE:\n",
    "                if np.random.rand() < 0.5:\n",
    "                    m = self.explorer_random\n",
    "                else:\n",
    "                    m = self.explorer_thirsty\n",
    "\n",
    "                exps, logs1 = m.collect_experiences(self.env)\n",
    "\n",
    "                m.update_parameters(exps)\n",
    "                logs2 = self.exploiter.update_parameters(exps)\n",
    "\n",
    "                if len(larger_buffer_r) >= 1:\n",
    "                    self._replay(self.explorer_thirsty, larger_buffer_r, cutoff=0.0)\n",
    "\n",
    "            elif mode == EXPLOIT_MODE:\n",
    "                exps, logs1 = self.exploiter.collect_experiences(self.env)\n",
    "\n",
    "                logs2 = self.exploiter.update_parameters(exps)\n",
    "\n",
    "                assert len(buffer_r) > 0, f'buffer_r should not be empty.'\n",
    "\n",
    "                cutoff = self.exploiter.args.bad_fit_threshold + self.exploiter.args.bad_fit_increment * (len(buffer_r) - 1)\n",
    "                \n",
    "                if not logs1['success'] and total_smooth_rs[-1] <= 0.5:\n",
    "                    fit = self._replay(self.exploiter, buffer_r, cutoff)\n",
    "                    fits.append(fit)\n",
    "\n",
    "                if len(buffer_r) == 0:\n",
    "                    print('empty')\n",
    "                    mode = EXPLORE_MODE\n",
    "                    self.explorer_thirsty.copy_machine(self.exploiter)\n",
    "                    self.explorer_random.copy_machine(self.temp_machine)\n",
    "                    self.temp_machine.copy_machine(self.exploiter)\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(f'Invalid mode: {mode}')\n",
    "            \n",
    "            logs = {**logs1, **logs2}\n",
    "\n",
    "            num_frames += logs[\"num_frames\"]\n",
    "\n",
    "            rewards.append(logs[\"return_per_episode\"])\n",
    "\n",
    "            if logs['success']:\n",
    "                self._add_sb_to_buffer(exps, buffer_r, self.exploiter.args.replay_buffer_capacity)\n",
    "                self._add_sb_to_buffer(exps, larger_buffer_r, self.exploiter.args.large_buffer_capacity)\n",
    "                mode = EXPLOIT_MODE\n",
    "            else:\n",
    "                self._add_sb_to_buffer(exps, buffer_no_r, self.exploiter.args.replay_buffer_capacity)\n",
    "\n",
    "            smooth_reward = np.mean(rewards[-SMOOTH_REWARD_WINDOW:])\n",
    "\n",
    "            total_smooth_rs.append(smooth_reward)\n",
    "\n",
    "            data = {'num_frames':num_frames, 'smooth_reward':smooth_reward,\n",
    "                'reward':logs[\"return_per_episode\"], 'episode':update}\n",
    "\n",
    "            pbar.set_postfix(data)\n",
    "\n",
    "            if not nonstop and smooth_reward >= self.exploiter.args.score_threshold:\n",
    "                    is_solved = True\n",
    "                    break\n",
    "    \n",
    "        if is_solved:\n",
    "            print('Solved!')\n",
    "\n",
    "        return total_num_frames, total_smooth_rs, fits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACModel(nn.Module):\n",
    "    def __init__(self, use_critic=False):\n",
    "        \"\"\"\n",
    "        Represents an Actor Crictic model that takes a 2d, multi-channeled\n",
    "        image as input.\n",
    "\n",
    "        Parameters\n",
    "        ----\n",
    "        num_actions : int\n",
    "\n",
    "                      The action space of the environment.\n",
    "                      The action space for DoorKey5x5 is 7-dimensional:\n",
    "                      0: turn left,\n",
    "                      1: turn right,\n",
    "                      2: forward,\n",
    "                      3: pickup an object,\n",
    "                      4: drop an object,\n",
    "                      5: activate an object,\n",
    "                      6: done completing task\n",
    "\n",
    "        use_critics : bool\n",
    "\n",
    "                      Critic network will be used in forward pass if flag is set\n",
    "                      to true.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.use_critic = use_critic\n",
    "\n",
    "        # Define actor's model\n",
    "        self.image_conv_actor = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 7)\n",
    "        )\n",
    "\n",
    "        # Define critic's model\n",
    "        if self.use_critic:\n",
    "            self.image_conv_critic = nn.Sequential(\n",
    "                nn.Conv2d(3, 16, (2, 2)),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d((2, 2)),\n",
    "                nn.Conv2d(16, 32, (2, 2)),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(32, 64, (2, 2)),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            self.critic = nn.Sequential(\n",
    "                nn.Linear(64, 64),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(64, 1)\n",
    "            )\n",
    "\n",
    "        # Initialize parameters correctly\n",
    "        self.apply(init_params)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the actor-critic network\n",
    "\n",
    "        Parameters\n",
    "        ----\n",
    "        obs : int tensor. Shape [Batch size, ImWidth, ImHeight, Channels]\n",
    "\n",
    "              input to the network.\n",
    "        ----\n",
    "\n",
    "        returns:\n",
    "\n",
    "        dist : torch.distribution\n",
    "            The distribution of actions from policy. A Categorical distribution\n",
    "            for discreet action spaces.\n",
    "        value : torch.Tensor (Batch size, 1)\n",
    "            value output by critic network\n",
    "        \"\"\"\n",
    "        obs = torch.tensor(obs).float() # convert to float tensor\n",
    "        if len(obs.shape) == 3:\n",
    "            obs = obs.unsqueeze(0) # add batch dimension if not already there\n",
    "            \n",
    "        conv_in = obs.transpose(1, 3).transpose(2, 3) # reshape into [b, c, h, w]\n",
    "\n",
    "        dist, value = None, None\n",
    "\n",
    "        x = self.image_conv_actor(conv_in)\n",
    "        embedding = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        x = self.actor(embedding)\n",
    "        dist = Categorical(logits=F.log_softmax(x, dim=1))\n",
    "\n",
    "        if self.use_critic:\n",
    "            y = self.image_conv_critic(conv_in)\n",
    "            embedding = y.reshape(y.shape[0], -1)\n",
    "\n",
    "            value = self.critic(embedding).squeeze(1)\n",
    "        else:\n",
    "            value = torch.zeros((x.shape[0], 1), device=x.device)\n",
    "        \n",
    "        return dist, value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/leg/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_frame to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_frame` for environment variables or `env.get_wrapper_attr('get_frame')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/leg/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.highlight to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.highlight` for environment variables or `env.get_wrapper_attr('highlight')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/leg/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.tile_size to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.tile_size` for environment variables or `env.get_wrapper_attr('tile_size')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/leg/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_pov to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_pov` for environment variables or `env.get_wrapper_attr('agent_pov')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = 7\n",
    "\n",
    "env = get_door_key_env(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start! Agent: PPO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]/var/folders/n5/sdw3gh1d1lj552x1k2x500mw0000gn/T/ipykernel_67945/2068944089.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  obs = torch.tensor(obs).float() # convert to float tensor\n",
      " 57%|    | 1717/3000 [22:54<17:07,  1.25it/s, num_frames=474550, smooth_reward=0.94, reward=1, policy_loss=-0.0489, value_loss=0.00771, episode=1717] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved!\n",
      "Start! Agent: RRR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 375/3000 [04:29<31:25,  1.39it/s, num_frames=78496, smooth_reward=0.94, reward=1, episode=375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 37\n",
    "max_steps = 3000\n",
    "\n",
    "agent_PPO = PPO(ACModel, env=env, args=Config(), seed=seed)\n",
    "num_frames_1, smooth_rs_1 = agent_PPO.train(max_steps)\n",
    "agent_RRR_2 = RRR(ACModel, env=env, args=Config(bad_fit_threshold=0.77, importance_sampling_clip=2.0), seed=seed)\n",
    "num_frames_2, smooth_rs_2, fits_2 = agent_RRR_2.train(max_steps)\n",
    "\n",
    "plt.plot(num_frames_1, smooth_rs_1, label='PPO')\n",
    "plt.plot(num_frames_2, smooth_rs_2, label='RRR, t = 0.77, c = 2.0')\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Average reward (smoothed)')\n",
    "plt.title(f'DoorKeyEnv, size = {size}, seed = {seed}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.8679245114326477,\n",
       " 0.8301886916160583,\n",
       " 0.8820754885673523,\n",
       " 0.9433962106704712,\n",
       " 0.8726415038108826,\n",
       " 0.7641509175300598,\n",
       " 0.75,\n",
       " 0.7971698045730591,\n",
       " 0.7735849022865295,\n",
       " 0.7547169923782349,\n",
       " 0.7264150977134705,\n",
       " 0.7264150977134705,\n",
       " 0.7311320900917053,\n",
       " 0.8207547068595886,\n",
       " 0.7783018946647644,\n",
       " 0.7547169923782349,\n",
       " 0.7547169923782349,\n",
       " 0.7877358198165894,\n",
       " 0.7877358198165894,\n",
       " 0.7735849022865295,\n",
       " 0.7311320900917053,\n",
       " 0.7594339847564697,\n",
       " 0.8066037893295288,\n",
       " 0.7122641801834106,\n",
       " 0.7547169923782349,\n",
       " 0.8254716992378235,\n",
       " 0.7641509175300598,\n",
       " 0.75,\n",
       " 0.8066037893295288,\n",
       " 0.7547169923782349,\n",
       " 0.7971698045730591,\n",
       " 0.8113207817077637,\n",
       " 0.7783018946647644,\n",
       " 0.7641509175300598,\n",
       " 0.7594339847564697,\n",
       " 0.7547169923782349,\n",
       " 0.7877358198165894,\n",
       " 0.75,\n",
       " 0.7122641801834106,\n",
       " 0.7216981053352356,\n",
       " 0.7783018946647644,\n",
       " 0.7688679099082947,\n",
       " 0.7594339847564697,\n",
       " 0.7830188870429993,\n",
       " 0.7735849022865295,\n",
       " 0.8113207817077637,\n",
       " 0.7547169923782349,\n",
       " 0.7452830076217651,\n",
       " 0.8066037893295288,\n",
       " 0.75,\n",
       " 0.7830188870429993,\n",
       " 0.801886796951294,\n",
       " 0.7311320900917053,\n",
       " 0.7405660152435303,\n",
       " 0.7877358198165894,\n",
       " 0.7311320900917053,\n",
       " 0.7688679099082947,\n",
       " 0.7735849022865295,\n",
       " 0.7877358198165894,\n",
       " 0.7688679099082947,\n",
       " 0.7405660152435303,\n",
       " 0.801886796951294,\n",
       " 0.8207547068595886,\n",
       " 0.8066037893295288,\n",
       " 0.7688679099082947,\n",
       " 0.7877358198165894,\n",
       " 0.7783018946647644,\n",
       " 0.75,\n",
       " 0.7264150977134705,\n",
       " 0.7547169923782349,\n",
       " 0.7783018946647644,\n",
       " 0.7594339847564697,\n",
       " 0.7735849022865295,\n",
       " 0.7783018946647644,\n",
       " 0.7358490824699402,\n",
       " 0.7688679099082947,\n",
       " 0.7547169923782349,\n",
       " 0.7735849022865295,\n",
       " 0.7452830076217651,\n",
       " 0.7311320900917053,\n",
       " 0.7594339847564697,\n",
       " 0.7924528121948242,\n",
       " 0.7924528121948242,\n",
       " 0.7830188870429993,\n",
       " 0.7877358198165894,\n",
       " 0.7783018946647644,\n",
       " 0.8301886916160583,\n",
       " 0.801886796951294,\n",
       " 0.7877358198165894,\n",
       " 0.8254716992378235,\n",
       " 0.7735849022865295,\n",
       " 0.801886796951294,\n",
       " 0.8349056839942932,\n",
       " 0.8254716992378235,\n",
       " 0.7877358198165894,\n",
       " 0.7641509175300598,\n",
       " 0.8160377144813538,\n",
       " 0.7641509175300598,\n",
       " 0.7688679099082947,\n",
       " 0.7688679099082947,\n",
       " 0.8066037893295288,\n",
       " 0.7830188870429993,\n",
       " 0.7830188870429993,\n",
       " 0.7924528121948242,\n",
       " 0.801886796951294,\n",
       " 0.7735849022865295,\n",
       " 0.7830188870429993,\n",
       " 0.7877358198165894,\n",
       " 0.7971698045730591,\n",
       " 0.7594339847564697,\n",
       " 0.7594339847564697,\n",
       " 0.7311320900917053,\n",
       " 0.7547169923782349,\n",
       " 0.7452830076217651,\n",
       " 0.7405660152435303,\n",
       " 0.7311320900917053,\n",
       " 0.7688679099082947,\n",
       " 0.7547169923782349,\n",
       " 0.7594339847564697,\n",
       " 0.7830188870429993,\n",
       " 0.7688679099082947,\n",
       " 0.7547169923782349,\n",
       " 0.7452830076217651,\n",
       " 0.7783018946647644,\n",
       " 0.7641509175300598,\n",
       " 0.7594339847564697,\n",
       " 0.7688679099082947,\n",
       " 0.7594339847564697,\n",
       " 0.7594339847564697,\n",
       " 0.7735849022865295,\n",
       " 0.7641509175300598,\n",
       " 0.7830188870429993,\n",
       " 0.7405660152435303,\n",
       " 0.7735849022865295,\n",
       " 0.7735849022865295,\n",
       " 0.7783018946647644,\n",
       " 0.8254716992378235,\n",
       " 0.801886796951294,\n",
       " 0.7783018946647644,\n",
       " 0.7688679099082947,\n",
       " 0.7971698045730591,\n",
       " 0.8160377144813538,\n",
       " 0.7877358198165894,\n",
       " 0.8160377144813538,\n",
       " 0.801886796951294,\n",
       " 0.7877358198165894,\n",
       " 0.7830188870429993,\n",
       " 0.8207547068595886,\n",
       " 0.7924528121948242,\n",
       " 0.7971698045730591,\n",
       " 0.8066037893295288,\n",
       " 0.801886796951294,\n",
       " 0.7971698045730591,\n",
       " 0.7877358198165894,\n",
       " 0.8254716992378235,\n",
       " 0.7735849022865295,\n",
       " 0.7594339847564697,\n",
       " 0.7924528121948242,\n",
       " 0.75,\n",
       " 0.7783018946647644,\n",
       " 0.7783018946647644,\n",
       " 0.7924528121948242,\n",
       " 0.801886796951294,\n",
       " 0.7830188870429993,\n",
       " 0.7924528121948242,\n",
       " 0.7641509175300598,\n",
       " 0.7735849022865295,\n",
       " 0.7783018946647644,\n",
       " 0.7971698045730591,\n",
       " 0.7924528121948242,\n",
       " 0.7830188870429993,\n",
       " 0.7735849022865295,\n",
       " 0.8254716992378235,\n",
       " 0.8443396091461182,\n",
       " 0.849056601524353,\n",
       " 0.7971698045730591,\n",
       " 0.8160377144813538,\n",
       " 0.8160377144813538,\n",
       " 0.7971698045730591,\n",
       " 0.8396226167678833,\n",
       " 0.8207547068595886,\n",
       " 0.849056601524353,\n",
       " 0.8301886916160583,\n",
       " 0.8301886916160583,\n",
       " 0.8207547068595886,\n",
       " 0.7783018946647644,\n",
       " 0.7688679099082947,\n",
       " 0.7877358198165894,\n",
       " 0.7783018946647644,\n",
       " 0.8066037893295288,\n",
       " 0.8301886916160583,\n",
       " 0.8632075190544128,\n",
       " 0.7924528121948242,\n",
       " 0.7830188870429993,\n",
       " 0.7830188870429993,\n",
       " 0.8396226167678833,\n",
       " 0.8396226167678833,\n",
       " 0.8349056839942932,\n",
       " 0.8679245114326477,\n",
       " 0.8301886916160583,\n",
       " 0.8349056839942932,\n",
       " 0.8066037893295288,\n",
       " 0.8301886916160583,\n",
       " 0.849056601524353,\n",
       " 0.8066037893295288,\n",
       " 0.8349056839942932,\n",
       " 0.8160377144813538,\n",
       " 0.8207547068595886,\n",
       " 0.8207547068595886,\n",
       " 0.8113207817077637,\n",
       " 0.8443396091461182,\n",
       " 0.8066037893295288,\n",
       " 0.8113207817077637,\n",
       " 0.849056601524353,\n",
       " 0.8443396091461182,\n",
       " 0.8254716992378235,\n",
       " 0.8349056839942932,\n",
       " 0.8113207817077637,\n",
       " 0.801886796951294,\n",
       " 0.8349056839942932,\n",
       " 0.8254716992378235,\n",
       " 0.7971698045730591,\n",
       " 0.8396226167678833,\n",
       " 0.8113207817077637,\n",
       " 0.8301886916160583,\n",
       " 0.7877358198165894,\n",
       " 0.7877358198165894,\n",
       " 0.8443396091461182,\n",
       " 0.7924528121948242,\n",
       " 0.8396226167678833,\n",
       " 0.8301886916160583,\n",
       " 0.8301886916160583,\n",
       " 0.8349056839942932,\n",
       " 0.8207547068595886,\n",
       " 0.8443396091461182,\n",
       " 0.8113207817077637,\n",
       " 0.7924528121948242,\n",
       " 0.7830188870429993,\n",
       " 0.801886796951294,\n",
       " 0.7924528121948242,\n",
       " 0.801886796951294,\n",
       " 0.8254716992378235,\n",
       " 0.8207547068595886,\n",
       " 0.7971698045730591,\n",
       " 0.8349056839942932,\n",
       " 0.7971698045730591,\n",
       " 0.8584905862808228,\n",
       " 0.8301886916160583,\n",
       " 0.8396226167678833,\n",
       " 0.8160377144813538,\n",
       " 0.8584905862808228,\n",
       " 0.801886796951294,\n",
       " 0.7830188870429993,\n",
       " 0.7971698045730591,\n",
       " 0.8160377144813538,\n",
       " 0.8396226167678833,\n",
       " 0.8160377144813538,\n",
       " 0.8254716992378235,\n",
       " 0.7877358198165894,\n",
       " 0.8301886916160583,\n",
       " 0.8349056839942932,\n",
       " 0.8349056839942932,\n",
       " 0.7688679099082947,\n",
       " 0.75,\n",
       " 0.8066037893295288,\n",
       " 0.7830188870429993,\n",
       " 0.7877358198165894,\n",
       " 0.7924528121948242,\n",
       " 0.8207547068595886,\n",
       " 0.8301886916160583,\n",
       " 0.7971698045730591,\n",
       " 0.801886796951294,\n",
       " 0.8349056839942932,\n",
       " 0.8396226167678833,\n",
       " 0.7971698045730591,\n",
       " 0.8113207817077637,\n",
       " 0.8113207817077637,\n",
       " 0.8301886916160583,\n",
       " 0.8160377144813538,\n",
       " 0.8349056839942932,\n",
       " 0.8349056839942932,\n",
       " 0.7971698045730591,\n",
       " 0.7783018946647644,\n",
       " 0.7783018946647644,\n",
       " 0.8254716992378235,\n",
       " 0.8254716992378235,\n",
       " 0.7924528121948242,\n",
       " 0.7924528121948242,\n",
       " 0.7830188870429993,\n",
       " 0.8207547068595886,\n",
       " 0.8254716992378235,\n",
       " 0.7688679099082947,\n",
       " 0.7924528121948242,\n",
       " 0.7924528121948242,\n",
       " 0.7783018946647644,\n",
       " 0.7594339847564697,\n",
       " 0.8207547068595886,\n",
       " 0.7877358198165894,\n",
       " 0.8066037893295288,\n",
       " 0.8349056839942932,\n",
       " 0.8726415038108826,\n",
       " 0.8066037893295288,\n",
       " 0.7971698045730591,\n",
       " 0.8349056839942932,\n",
       " 0.849056601524353,\n",
       " 0.8396226167678833,\n",
       " 0.8537735939025879,\n",
       " 0.849056601524353,\n",
       " 0.8254716992378235,\n",
       " 0.8113207817077637,\n",
       " 0.8632075190544128,\n",
       " 0.8160377144813538,\n",
       " 0.8113207817077637,\n",
       " 0.8396226167678833,\n",
       " 0.8254716992378235,\n",
       " 0.8160377144813538,\n",
       " 0.8349056839942932,\n",
       " 0.8349056839942932,\n",
       " 0.8537735939025879,\n",
       " 0.849056601524353,\n",
       " 0.8584905862808228,\n",
       " 0.849056601524353,\n",
       " 0.8396226167678833,\n",
       " 0.8396226167678833,\n",
       " 0.7971698045730591,\n",
       " 0.8443396091461182,\n",
       " 0.8254716992378235,\n",
       " 0.7971698045730591,\n",
       " 0.8301886916160583,\n",
       " 0.849056601524353,\n",
       " 0.8207547068595886,\n",
       " 0.7971698045730591,\n",
       " 0.801886796951294,\n",
       " 0.8584905862808228,\n",
       " 0.8537735939025879,\n",
       " 0.8443396091461182,\n",
       " 0.8207547068595886,\n",
       " 0.849056601524353,\n",
       " 0.8632075190544128,\n",
       " 0.8254716992378235,\n",
       " 0.8301886916160583,\n",
       " 0.8160377144813538,\n",
       " 0.8537735939025879,\n",
       " 0.8160377144813538,\n",
       " 0.8254716992378235,\n",
       " 0.7877358198165894,\n",
       " 0.8254716992378235,\n",
       " 0.7971698045730591,\n",
       " 0.8207547068595886,\n",
       " 0.8066037893295288,\n",
       " 0.8113207817077637,\n",
       " 0.801886796951294,\n",
       " 0.8066037893295288,\n",
       " 0.7971698045730591,\n",
       " 0.8113207817077637,\n",
       " 0.849056601524353,\n",
       " 0.8301886916160583,\n",
       " 0.8160377144813538,\n",
       " 0.8207547068595886,\n",
       " 0.8396226167678833,\n",
       " 0.8349056839942932,\n",
       " 0.8207547068595886,\n",
       " 0.7877358198165894,\n",
       " 0.8113207817077637,\n",
       " 0.8160377144813538,\n",
       " 0.7783018946647644,\n",
       " 0.8113207817077637,\n",
       " 0.7783018946647644,\n",
       " 0.8113207817077637,\n",
       " 0.8066037893295288,\n",
       " 0.7971698045730591,\n",
       " 0.801886796951294,\n",
       " 0.7877358198165894,\n",
       " 0.7688679099082947,\n",
       " 0.7735849022865295,\n",
       " 0.7924528121948242,\n",
       " 0.75,\n",
       " 0.7783018946647644,\n",
       " 0.7735849022865295,\n",
       " 0.801886796951294,\n",
       " 0.7783018946647644,\n",
       " 0.7830188870429993,\n",
       " 0.7877358198165894,\n",
       " 0.7783018946647644,\n",
       " 0.7971698045730591,\n",
       " 0.7735849022865295,\n",
       " 0.7735849022865295,\n",
       " 0.7924528121948242,\n",
       " 0.8066037893295288,\n",
       " 0.7735849022865295,\n",
       " 0.7783018946647644,\n",
       " 0.7877358198165894,\n",
       " 0.7594339847564697,\n",
       " 0.7688679099082947,\n",
       " 0.7594339847564697,\n",
       " 0.7877358198165894,\n",
       " 0.8301886916160583,\n",
       " 0.7688679099082947,\n",
       " 0.7877358198165894,\n",
       " 0.801886796951294,\n",
       " 0.7877358198165894,\n",
       " 0.8113207817077637,\n",
       " 0.7924528121948242,\n",
       " 0.8113207817077637,\n",
       " 0.8301886916160583,\n",
       " 0.8160377144813538,\n",
       " 0.7783018946647644,\n",
       " 0.75,\n",
       " 0.7877358198165894,\n",
       " 0.7641509175300598,\n",
       " 0.7783018946647644,\n",
       " 0.7924528121948242,\n",
       " 0.8443396091461182,\n",
       " 0.7877358198165894,\n",
       " 0.7735849022865295,\n",
       " 0.7830188870429993,\n",
       " 0.7924528121948242,\n",
       " 0.7547169923782349,\n",
       " 0.7594339847564697,\n",
       " 0.7783018946647644,\n",
       " 0.7688679099082947,\n",
       " 0.7971698045730591,\n",
       " 0.75,\n",
       " 0.7830188870429993,\n",
       " 0.7877358198165894,\n",
       " 0.8113207817077637,\n",
       " 0.7830188870429993,\n",
       " 0.8160377144813538,\n",
       " 0.7924528121948242,\n",
       " 0.7688679099082947,\n",
       " 0.7735849022865295,\n",
       " 0.7735849022865295,\n",
       " 0.7830188870429993,\n",
       " 0.7830188870429993,\n",
       " 0.7783018946647644,\n",
       " 0.7735849022865295,\n",
       " 0.7452830076217651,\n",
       " 0.7924528121948242,\n",
       " 0.8113207817077637,\n",
       " 0.849056601524353,\n",
       " 0.7830188870429993,\n",
       " 0.801886796951294,\n",
       " 0.7688679099082947,\n",
       " 0.8066037893295288,\n",
       " 0.7641509175300598,\n",
       " 0.7830188870429993,\n",
       " 0.7877358198165894,\n",
       " 0.8160377144813538,\n",
       " 0.8207547068595886,\n",
       " 0.7924528121948242,\n",
       " 0.8632075190544128,\n",
       " 0.7877358198165894,\n",
       " 0.801886796951294,\n",
       " 0.7877358198165894,\n",
       " 0.7971698045730591,\n",
       " 0.7735849022865295,\n",
       " 0.7688679099082947,\n",
       " 0.7688679099082947,\n",
       " 0.8113207817077637,\n",
       " 0.7971698045730591,\n",
       " 0.7783018946647644,\n",
       " 0.8066037893295288,\n",
       " 0.8160377144813538,\n",
       " 0.8113207817077637,\n",
       " 0.7971698045730591,\n",
       " 0.8113207817077637,\n",
       " 0.8160377144813538,\n",
       " 0.8066037893295288,\n",
       " 0.7452830076217651,\n",
       " 0.7547169923782349,\n",
       " 0.8066037893295288,\n",
       " 0.7547169923782349,\n",
       " 0.75,\n",
       " 0.7877358198165894,\n",
       " 0.7971698045730591,\n",
       " 0.7688679099082947,\n",
       " 0.7452830076217651,\n",
       " 0.7783018946647644,\n",
       " 0.8113207817077637,\n",
       " 0.7594339847564697,\n",
       " 0.801886796951294,\n",
       " 0.7735849022865295,\n",
       " 0.8160377144813538,\n",
       " 0.8113207817077637,\n",
       " 0.7971698045730591,\n",
       " 0.7877358198165894,\n",
       " 0.8301886916160583,\n",
       " 0.8207547068595886,\n",
       " 0.849056601524353,\n",
       " 0.8066037893295288,\n",
       " 0.8113207817077637,\n",
       " 0.7877358198165894,\n",
       " 0.7877358198165894,\n",
       " 0.7688679099082947,\n",
       " 0.801886796951294,\n",
       " 0.8349056839942932,\n",
       " 0.8254716992378235,\n",
       " 0.8349056839942932,\n",
       " 0.8066037893295288,\n",
       " 0.8113207817077637,\n",
       " 0.801886796951294,\n",
       " 0.7924528121948242,\n",
       " 0.8254716992378235,\n",
       " 0.7924528121948242,\n",
       " 0.8160377144813538,\n",
       " 0.7735849022865295,\n",
       " 0.8207547068595886,\n",
       " 0.8066037893295288,\n",
       " 0.7783018946647644,\n",
       " 0.7971698045730591,\n",
       " 0.7830188870429993,\n",
       " 0.7594339847564697,\n",
       " 0.7877358198165894,\n",
       " 0.7924528121948242,\n",
       " 0.9957982897758484,\n",
       " 0.7641509175300598,\n",
       " 0.7971698045730591,\n",
       " 0.7830188870429993,\n",
       " 0.9075630307197571,\n",
       " 0.7877358198165894,\n",
       " 0.9075630307197571,\n",
       " 0.8781512379646301,\n",
       " 0.7877358198165894,\n",
       " 0.8537735939025879,\n",
       " 0.7877358198165894,\n",
       " 0.7971698045730591,\n",
       " 0.8529411554336548,\n",
       " 0.8781512379646301,\n",
       " 0.8613445162773132,\n",
       " 0.8655462265014648,\n",
       " 0.819327712059021,\n",
       " 0.831932783126831,\n",
       " 0.7641509175300598,\n",
       " 0.7547169923782349,\n",
       " 0.7688679099082947,\n",
       " 0.8529411554336548,\n",
       " 0.7594339847564697,\n",
       " 0.8529411554336548,\n",
       " 0.7830188870429993,\n",
       " 0.7877358198165894,\n",
       " 0.8235294222831726,\n",
       " 0.75,\n",
       " 0.8361344337463379,\n",
       " 0.8361344337463379,\n",
       " 0.7877358198165894,\n",
       " 0.7924528121948242,\n",
       " 0.831932783126831,\n",
       " 0.8109243512153625,\n",
       " 0.7924528121948242,\n",
       " 0.8067227005958557,\n",
       " 0.7735849022865295,\n",
       " 0.8254716992378235,\n",
       " 0.8254716992378235,\n",
       " 0.8066037893295288,\n",
       " 0.7971698045730591,\n",
       " 0.7877358198165894,\n",
       " 0.8823529481887817,\n",
       " 0.8445377945899963,\n",
       " 0.831932783126831,\n",
       " 0.8403361439704895,\n",
       " 0.8025209903717041,\n",
       " 0.7877358198165894,\n",
       " 0.831932783126831,\n",
       " 0.8066037893295288,\n",
       " 0.819327712059021,\n",
       " 0.8067227005958557,\n",
       " 0.7971698045730591,\n",
       " 0.7641509175300598,\n",
       " 0.7452830076217651,\n",
       " 0.7452830076217651,\n",
       " 0.7358490824699402,\n",
       " 0.7547169923782349,\n",
       " 0.7641509175300598,\n",
       " 0.8445377945899963,\n",
       " 0.8277310729026794,\n",
       " 0.8067227005958557,\n",
       " 0.7641509175300598,\n",
       " 0.8067227005958557,\n",
       " 0.7594339847564697,\n",
       " 0.831932783126831,\n",
       " 0.7783018946647644,\n",
       " 0.8235294222831726,\n",
       " 0.7877358198165894,\n",
       " 0.7547169923782349,\n",
       " 0.8254716992378235,\n",
       " 0.7783018946647644,\n",
       " 0.7924528121948242,\n",
       " 0.7877358198165894,\n",
       " 0.8113207817077637,\n",
       " 0.8151260614395142,\n",
       " 0.8235294222831726,\n",
       " 0.801886796951294,\n",
       " 0.8151260614395142,\n",
       " 0.8066037893295288,\n",
       " 0.7783018946647644,\n",
       " 0.7877358198165894,\n",
       " 0.75,\n",
       " 0.8361344337463379,\n",
       " 0.8025209903717041,\n",
       " 0.7773109078407288,\n",
       " 0.8066037893295288,\n",
       " 0.8254716992378235,\n",
       " 0.8025209903717041,\n",
       " 0.8067227005958557,\n",
       " 0.7773109078407288,\n",
       " 0.7857142686843872,\n",
       " 0.8066037893295288,\n",
       " 0.756302535533905,\n",
       " 0.7971698045730591,\n",
       " 0.7647058963775635,\n",
       " 0.7830188870429993,\n",
       " 0.7815126180648804,\n",
       " 0.8207547068595886,\n",
       " 0.7983193397521973,\n",
       " 0.7688679099082947,\n",
       " 0.7830188870429993,\n",
       " 0.7830188870429993,\n",
       " 0.7971698045730591,\n",
       " 0.7877358198165894,\n",
       " 0.7941176295280457,\n",
       " 0.7899159789085388,\n",
       " 0.8025209903717041,\n",
       " 0.8066037893295288,\n",
       " 0.801886796951294,\n",
       " 0.8235294222831726,\n",
       " 0.7924528121948242,\n",
       " 0.7983193397521973,\n",
       " 0.7924528121948242,\n",
       " 0.7783018946647644,\n",
       " 0.7941176295280457,\n",
       " 0.7689075469970703,\n",
       " 0.7773109078407288,\n",
       " 0.7605041861534119,\n",
       " 0.8254716992378235,\n",
       " 0.7971698045730591,\n",
       " 0.7452830076217651,\n",
       " 0.7547169923782349,\n",
       " 0.7830188870429993,\n",
       " 0.8151260614395142,\n",
       " 0.7877358198165894,\n",
       " 0.7688679099082947,\n",
       " 0.7899159789085388,\n",
       " 0.7735849022865295,\n",
       " 0.8066037893295288,\n",
       " 0.7688679099082947,\n",
       " 0.7605041861534119,\n",
       " 0.8025209903717041,\n",
       " 0.8109243512153625,\n",
       " 0.7731092572212219,\n",
       " 0.7521008253097534,\n",
       " 0.7773109078407288,\n",
       " 0.7877358198165894,\n",
       " 0.8254716992378235,\n",
       " 0.7899159789085388,\n",
       " 0.7731092572212219,\n",
       " 0.7783018946647644,\n",
       " 0.7731092572212219,\n",
       " 0.8066037893295288,\n",
       " 0.756302535533905,\n",
       " 0.7641509175300598,\n",
       " 0.7857142686843872,\n",
       " 0.8207547068595886,\n",
       " 0.7877358198165894,\n",
       " 0.7735849022865295,\n",
       " 0.8361344337463379,\n",
       " 0.8113207817077637,\n",
       " 0.7689075469970703,\n",
       " 0.7689075469970703,\n",
       " 0.7647058963775635,\n",
       " 0.8066037893295288,\n",
       " 0.7924528121948242,\n",
       " 0.7815126180648804,\n",
       " 0.7783018946647644,\n",
       " 0.9671052694320679,\n",
       " 0.743697464466095,\n",
       " 0.8881579041481018,\n",
       " 0.7857142686843872,\n",
       " 0.756302535533905,\n",
       " 0.7647058963775635,\n",
       " 0.7773109078407288,\n",
       " 0.801886796951294,\n",
       " 0.9013158082962036,\n",
       " 0.7899159789085388,\n",
       " 0.8025209903717041,\n",
       " 0.831932783126831,\n",
       " 0.8349056839942932,\n",
       " 0.8207547068595886,\n",
       " 0.9473684430122375,\n",
       " 0.9210526347160339,\n",
       " 0.9210526347160339,\n",
       " 0.8025209903717041,\n",
       " 0.8815789222717285,\n",
       " 0.8445377945899963,\n",
       " 0.7924528121948242,\n",
       " 0.8947368264198303,\n",
       " 0.9078947305679321,\n",
       " 0.8486841917037964,\n",
       " 0.831932783126831,\n",
       " 0.8113207817077637,\n",
       " 0.8618420958518982,\n",
       " 0.7830188870429993,\n",
       " 0.95333331823349,\n",
       " 0.8815789222717285,\n",
       " 0.875,\n",
       " 0.8618420958518982,\n",
       " 0.7828947305679321,\n",
       " 0.8355262875556946,\n",
       " 0.831932783126831,\n",
       " 0.9133333563804626,\n",
       " 0.8109243512153625,\n",
       " 0.8349056839942932,\n",
       " 0.8999999761581421,\n",
       " 0.831932783126831,\n",
       " 0.8109243512153625,\n",
       " 0.7941176295280457,\n",
       " 0.7924528121948242,\n",
       " 0.8151260614395142,\n",
       " 0.8277310729026794,\n",
       " 0.801886796951294,\n",
       " 0.8881579041481018,\n",
       " 0.8846153616905212,\n",
       " 0.8025209903717041,\n",
       " 0.8733333349227905,\n",
       " 0.7971698045730591,\n",
       " 0.8552631735801697,\n",
       " 0.8403361439704895,\n",
       " 0.8780487775802612,\n",
       " 0.807692289352417,\n",
       " 0.8866666555404663,\n",
       " 0.8600000143051147,\n",
       " 0.8947368264198303,\n",
       " 0.8223684430122375,\n",
       " 0.8461538553237915,\n",
       " 0.8536585569381714,\n",
       " 0.8066666722297668,\n",
       " 0.8292682766914368,\n",
       " 0.8109243512153625,\n",
       " 0.807692289352417,\n",
       " 0.8684210777282715,\n",
       " 0.8292682766914368,\n",
       " 0.7692307829856873,\n",
       " 0.8421052694320679,\n",
       " 0.8157894611358643,\n",
       " 0.7933333516120911,\n",
       " 0.9295774698257446,\n",
       " 0.9238095283508301,\n",
       " 0.9238095283508301,\n",
       " 0.8484848737716675,\n",
       " 0.7804877758026123,\n",
       " 0.8333333134651184,\n",
       " 0.8881579041481018,\n",
       " 0.8684210777282715,\n",
       " 0.9142857193946838,\n",
       " 0.8403361439704895,\n",
       " 0.8552631735801697,\n",
       " 0.9718309640884399,\n",
       " 0.9577465057373047,\n",
       " 0.8873239159584045,\n",
       " 0.9090909361839294,\n",
       " 0.8025209903717041,\n",
       " 0.8552631735801697,\n",
       " 0.9154929518699646,\n",
       " 0.9012345671653748,\n",
       " 0.9610389471054077,\n",
       " 0.9066147804260254,\n",
       " 0.8636363744735718,\n",
       " 0.9350649118423462,\n",
       " 0.9153439402580261,\n",
       " 0.9154929518699646,\n",
       " 0.8765432238578796,\n",
       " 0.9260700345039368,\n",
       " 0.8395061492919922,\n",
       " 0.9428571462631226,\n",
       " 0.9182879328727722,\n",
       " 0.9100528955459595,\n",
       " 0.9143968820571899,\n",
       " 0.9873417615890503,\n",
       " 0.9675324559211731,\n",
       " 0.9025974273681641,\n",
       " 0.9295774698257446,\n",
       " 0.9333333373069763,\n",
       " 0.8881579041481018,\n",
       " 0.9481481313705444,\n",
       " 0.9481481313705444,\n",
       " 0.9428571462631226,\n",
       " 0.9296296238899231,\n",
       " 0.9181034564971924,\n",
       " 0.9037036895751953,\n",
       " 0.9409282803535461,\n",
       " 0.9333333373069763,\n",
       " 0.9281768202781677,\n",
       " 0.9100528955459595,\n",
       " 0.8663793206214905,\n",
       " 0.8472222089767456,\n",
       " 0.8945147395133972,\n",
       " 0.9238095283508301,\n",
       " 0.9142857193946838,\n",
       " 0.928909957408905,\n",
       " 1.0,\n",
       " 0.9146919250488281,\n",
       " 0.9904761910438538,\n",
       " 0.9047619104385376,\n",
       " 0.887159526348114,\n",
       " 0.9281437397003174,\n",
       " 0.9488189220428467,\n",
       " 0.9409449100494385,\n",
       " 0.9428571462631226,\n",
       " 0.8987341523170471,\n",
       " 1.0,\n",
       " 0.8472222089767456,\n",
       " 0.9454545378684998,\n",
       " 1.0,\n",
       " 0.8867924809455872,\n",
       " 0.910179615020752,\n",
       " 0.8999999761581421,\n",
       " 0.9444444179534912,\n",
       " 0.9362549781799316,\n",
       " 0.9322709441184998,\n",
       " 0.9375,\n",
       " 0.8931623697280884,\n",
       " 0.8681318759918213,\n",
       " 0.9788732528686523,\n",
       " 0.9196428656578064,\n",
       " 0.9714285731315613,\n",
       " 0.9942528605461121,\n",
       " 0.94017094373703,\n",
       " 0.9779411554336548,\n",
       " 0.970588207244873,\n",
       " 0.9163346886634827,\n",
       " 0.8839285969734192,\n",
       " 0.9358974099159241,\n",
       " 0.954023003578186,\n",
       " 0.94017094373703,\n",
       " 0.982758641242981,\n",
       " 0.94017094373703,\n",
       " 0.9425287246704102,\n",
       " 0.8839285969734192,\n",
       " 0.8818897604942322,\n",
       " 0.959770143032074,\n",
       " 0.9264705777168274,\n",
       " 0.9870129823684692,\n",
       " 0.9014084339141846,\n",
       " 0.8976377844810486,\n",
       " 0.8928571343421936,\n",
       " 0.8700787425041199,\n",
       " 0.9714285731315613,\n",
       " 0.9252873659133911,\n",
       " 0.9567099809646606,\n",
       " 0.9428571462631226,\n",
       " 0.959770143032074,\n",
       " 0.9017857313156128,\n",
       " 0.9886363744735718,\n",
       " 1.0,\n",
       " 0.8571428656578064,\n",
       " 0.9220778942108154,\n",
       " 0.9886363744735718,\n",
       " 0.9444444179534912,\n",
       " 0.9273504018783569,\n",
       " 0.939393937587738,\n",
       " 0.9590163826942444,\n",
       " 0.9090909361839294,\n",
       " 0.9022988677024841,\n",
       " 0.9188033938407898,\n",
       " 0.9590163826942444,\n",
       " 0.9090909361839294,\n",
       " 0.9485294222831726,\n",
       " 0.9444444179534912,\n",
       " 1.0,\n",
       " 0.8888888955116272,\n",
       " 0.9111111164093018,\n",
       " 0.948113203048706,\n",
       " 1.0,\n",
       " 0.9571428298950195,\n",
       " 0.9965277910232544,\n",
       " 0.9386792182922363,\n",
       " 0.8852459192276001,\n",
       " 0.8909090757369995,\n",
       " 0.963302731513977,\n",
       " 0.949999988079071,\n",
       " 0.9724770784378052,\n",
       " 0.9954338073730469,\n",
       " 0.9433962106704712,\n",
       " 0.9816513657569885,\n",
       " 0.9816513657569885,\n",
       " 0.9411764740943909,\n",
       " 1.0,\n",
       " 0.9411764740943909,\n",
       " 0.9726027250289917,\n",
       " 0.9965277910232544,\n",
       " 0.9724770784378052,\n",
       " 0.9965277910232544,\n",
       " 0.9724770784378052,\n",
       " 0.9661017060279846,\n",
       " 0.9726027250289917,\n",
       " 0.9117646813392639,\n",
       " 0.9292452931404114,\n",
       " 0.9492753744125366,\n",
       " 0.913241982460022,\n",
       " 0.9965277910232544,\n",
       " 0.948113203048706,\n",
       " 0.9391891956329346,\n",
       " 0.9459459185600281,\n",
       " 0.9032257795333862,\n",
       " 0.84375,\n",
       " 0.949999988079071,\n",
       " 0.9572649598121643,\n",
       " 0.9826388955116272,\n",
       " 0.949999988079071,\n",
       " 0.9318181872367859,\n",
       " 0.932584285736084,\n",
       " 0.9491525292396545,\n",
       " 0.90625,\n",
       " 0.9449541568756104,\n",
       " 0.9357798099517822,\n",
       " 0.9082568883895874,\n",
       " 0.8974359035491943,\n",
       " 0.9161290526390076,\n",
       " 0.9661017060279846,\n",
       " 0.8666666746139526,\n",
       " 0.9322034120559692,\n",
       " 0.9965277910232544,\n",
       " 1.0,\n",
       " 0.9017093777656555,\n",
       " 1.0,\n",
       " 0.9130434989929199,\n",
       " 0.9800000190734863,\n",
       " 0.9399999976158142,\n",
       " 0.9514563083648682,\n",
       " 0.9350649118423462,\n",
       " 0.9223300814628601,\n",
       " 0.9661017060279846,\n",
       " 0.9861111044883728,\n",
       " 0.8426966071128845,\n",
       " 0.9835164546966553,\n",
       " 0.9450549483299255,\n",
       " 0.9558823704719543,\n",
       " 0.8983050584793091,\n",
       " 0.890625,\n",
       " 0.9583333134651184,\n",
       " 0.9200000166893005,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.9449999928474426,\n",
       " 0.9599999785423279,\n",
       " 0.920634925365448,\n",
       " 0.8543689250946045,\n",
       " 0.9482758641242981,\n",
       " 0.970588207244873,\n",
       " 0.9876543283462524,\n",
       " 0.9818181991577148,\n",
       " 0.9482758641242981,\n",
       " 0.8844221234321594,\n",
       " 0.9411764740943909,\n",
       " 0.9242424368858337,\n",
       " 0.9896551966667175,\n",
       " 0.934482753276825,\n",
       " 1.0,\n",
       " 0.9184397459030151,\n",
       " 0.9583333134651184,\n",
       " 0.9908257126808167,\n",
       " 0.9793814420700073,\n",
       " 0.9375,\n",
       " 0.9816513657569885,\n",
       " 0.8828125,\n",
       " 1.0,\n",
       " 0.9793814420700073,\n",
       " 0.9514563083648682,\n",
       " 0.9440000057220459,\n",
       " 0.9508196711540222,\n",
       " 0.9427312612533569,\n",
       " 0.9626168012619019,\n",
       " 0.9626168012619019,\n",
       " 0.9722222089767456,\n",
       " 0.9718309640884399,\n",
       " 0.9470587968826294,\n",
       " 0.9765258431434631,\n",
       " 0.8888888955116272,\n",
       " 0.9343065619468689,\n",
       " 0.9305555820465088,\n",
       " 0.9436619877815247,\n",
       " 0.95652174949646,\n",
       " 0.938144326210022,\n",
       " 0.9813084006309509,\n",
       " 0.9626168012619019,\n",
       " 0.9532710313796997,\n",
       " 0.9028339982032776,\n",
       " 0.9166666865348816,\n",
       " 0.9833333492279053,\n",
       " 0.936170220375061,\n",
       " 1.0,\n",
       " 0.9611111283302307,\n",
       " 0.9252336621284485,\n",
       " 0.9252336621284485,\n",
       " 0.9530516266822815,\n",
       " 0.9117646813392639,\n",
       " 0.949999988079071,\n",
       " 0.9830508232116699,\n",
       " 0.9802631735801697,\n",
       " 0.9555555582046509,\n",
       " ...]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
