{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.14)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "import torch.nn.functional as F\n",
    "import minigrid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from tqdm.notebook import tqdm\n",
    "from minigrid.envs.doorkey import DoorKeyEnv\n",
    "import pandas as pd\n",
    "from gym.envs.registration import registry, register\n",
    "import random\n",
    "from typing_extensions import Self\n",
    "import matplotlib.pyplot as plt\n",
    "from minigrid.wrappers import ObservationWrapper\n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "from typing import Any\n",
    "from copy import deepcopy\n",
    "from collections import deque\n",
    "from minigrid.wrappers import ObservationWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Returns the device to use for training.\n",
    "    \"\"\"\n",
    "    #return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr/blob/master/model.py\n",
    "def init_params(m):\n",
    "    \"\"\"\n",
    "    Initialize parameters of the network.\n",
    "    m: torch.nn.Module\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Linear\") != -1:\n",
    "        m.weight.data.normal_(0, 1)\n",
    "        m.weight.data *= 1 / torch.sqrt(m.weight.data.pow(2).sum(1, keepdim=True))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "class MyDoorKeyEnv(DoorKeyEnv):\n",
    "    def __init__(self, size):\n",
    "        self.render_mode = \"rgb_array\"\n",
    "        super().__init__(size=size)\n",
    "\n",
    "    def _reward(self):\n",
    "        \"\"\"\n",
    "        Compute the reward to be given upon success\n",
    "        \"\"\"\n",
    "        return 1\n",
    "\n",
    "class ImgObsWrapper(ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Use the image as the only observation output, no language/mission.\n",
    "\n",
    "    Parameters:\n",
    "    - env (gym.Env): The environment to wrap.\n",
    "\n",
    "    Methods:\n",
    "    - observation(self, obs): Returns the image from the observation.\n",
    "    - reset(self): Resets the environment and returns the initial observation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        Initializes the ImgObsWrapper with the given environment.\n",
    "\n",
    "        Parameters:\n",
    "        - env (gym.Env): The environment whose observations are to be wrapped.\n",
    "        \"\"\"\n",
    "        super().__init__(env)\n",
    "        self.observation_space = env.observation_space.spaces[\"image\"]\n",
    "\n",
    "    def observation(self, obs):\n",
    "        \"\"\"\n",
    "        Extracts and returns the image data from the observation.\n",
    "\n",
    "        Parameters:\n",
    "        - obs (dict or tuple): The original observation from the environment, which could be either\n",
    "        a dictionary or a tuple containing a dictionary.\n",
    "\n",
    "        Returns:\n",
    "        - np.ndarray: The image data extracted from the observation.\n",
    "        \"\"\"\n",
    "        if type(obs) == tuple:\n",
    "            return obs[0][\"image\"]\n",
    "        return obs[\"image\"]\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment and returns the initial observation image.\n",
    "\n",
    "        Returns:\n",
    "        - np.ndarray: The initial observation image of the reset environment.\n",
    "        \"\"\"\n",
    "        obs = super().reset()\n",
    "        return obs[0]\n",
    "\n",
    "def get_door_key_env(size):\n",
    "    \"\"\"\n",
    "    Returns a DoorKeyEnv environment with the given size.\n",
    "    \"\"\"\n",
    "    env = MyDoorKeyEnv(size=size)\n",
    "    env = ImgObsWrapper(env)\n",
    "\n",
    "    env.reset()\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # get an RGB image corresponding to the whole environment or the agent's point of view (https://github.com/Farama-Foundation/Minigrid/blob/master/minigrid/minigrid_env.py#L716)\n",
    "    #            highlight (bool): If true, the agent's field of view or point of view is highlighted with a lighter gray color.\n",
    "    #            tile_size (int): How many pixels will form a tile from the NxM grid.\n",
    "    #            agent_pov (bool): If true, the rendered frame will only contain the point of view of the agent.\n",
    "    frame = env.get_frame(highlight=env.highlight, tile_size=env.tile_size, agent_pov=env.agent_pov)\n",
    "    # show an image to the notebook.\n",
    "    plt.imshow(frame)\n",
    "\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Stores algorithmic hyperparameters.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                score_threshold=0.93,\n",
    "                discount=0.995,\n",
    "                lr=1e-3,\n",
    "                max_grad_norm=0.5,\n",
    "                log_interval=10,\n",
    "                gae_lambda=0.95,\n",
    "                clip_ratio=0.2,\n",
    "                target_kl=0.01,\n",
    "                train_ac_iters=5,\n",
    "                use_discounted_reward=True,\n",
    "                use_gae=True,\n",
    "                importance_sampling_clip=2.0,\n",
    "                bad_fit_threshold=0.8,\n",
    "                bad_fit_increment=None,\n",
    "                replay_buffer_capacity=10,\n",
    "                large_buffer_capacity=20):\n",
    "\n",
    "        self.score_threshold = score_threshold # criterion for early stopping. If the rolling average reward (over the last 100 episodes) is greater than it, it ends.\n",
    "        self.discount = discount # discount factor\n",
    "        self.lr = lr # learning rate\n",
    "        self.max_grad_norm = max_grad_norm # the maximum gradient norm (https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
    "        self.log_interval = log_interval # logging interval\n",
    "        self.clip_ratio = clip_ratio # clip_ratio of PPO.\n",
    "        self.target_kl = target_kl # target KL divergence for early stoping train_ac_iters for PPO\n",
    "        self.train_ac_iters = train_ac_iters # how many time to train ac_model using current computed old_logps\n",
    "        self.gae_lambda=gae_lambda # lambda in Generalized Advantage Estimation (GAE)\n",
    "        self.use_discounted_reward=use_discounted_reward # whether use discounted reward or not.\n",
    "        self.use_gae = use_gae # whether to use GAE or not.\n",
    "        self.importance_sampling_clip = importance_sampling_clip # importance sampling clip threshold\n",
    "        self.bad_fit_threshold = bad_fit_threshold # threshold for bad fit.\n",
    "        if bad_fit_increment is None:\n",
    "            bad_fit_increment = (1.0 - bad_fit_threshold) / replay_buffer_capacity\n",
    "        self.bad_fit_increment = bad_fit_increment # increment for bad fit.\n",
    "        self.replay_buffer_capacity = replay_buffer_capacity # capacity of replay buffer.\n",
    "        self.large_buffer_capacity = large_buffer_capacity # capacity of large replay buffer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "    def __init__(self, entropy_coef, init_model:nn.Module, args:Config=None):\n",
    "        \"\"\"\n",
    "        A Machine object consists of a Model and its entropy_coef\n",
    "\n",
    "        Args:\n",
    "            entropy_coef: Entropy coefficient.\n",
    "            init_model: Initial model.\n",
    "            args\n",
    "        \"\"\"\n",
    "        if args is None:\n",
    "            self.args = Config()\n",
    "        else:\n",
    "            self.args = args\n",
    "\n",
    "        self.model = init_model\n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.args.lr)\n",
    "        self.coef = entropy_coef\n",
    "        self.device = get_device()\n",
    "\n",
    "    def copy_model(self, other_model:nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Copy state dict from 'model'. Reset rs.\n",
    "        \"\"\"\n",
    "        state_dict = other_model.state_dict()\n",
    "        for key, v in state_dict.items():\n",
    "            if key in self.model.state_dict():\n",
    "                self.model.state_dict()[key].copy_(v)\n",
    "\n",
    "    def copy_machine(self, other:Self) -> None:\n",
    "        \"\"\"\n",
    "        Copy state dict from 'other'. Reset rs.\n",
    "        \"\"\"\n",
    "        self.copy_model(other.model)\n",
    "\n",
    "    def _compute_discounted_return(self, rewards):\n",
    "        \"\"\"\n",
    "            rewards: reward obtained at timestep.  Shape: (T,)\n",
    "            discount: discount factor. float\n",
    "\n",
    "        ----\n",
    "        returns: sum of discounted rewards. Shape: (T,)\n",
    "        \"\"\"\n",
    "        returns = torch.zeros(*rewards.shape, device=self.device)\n",
    "\n",
    "        R = 0\n",
    "        for t in reversed(range((rewards.shape[0]))):\n",
    "            R = rewards[t] + self.args.discount * R\n",
    "            returns[t] = R\n",
    "        return returns\n",
    "\n",
    "    def _compute_advantage_gae(self, values, rewards, T):\n",
    "        \"\"\"\n",
    "        Compute Adavantage wiht GAE. See Section 4.4.2 in the lecture notes.\n",
    "\n",
    "        values: value at each timestep (T,)\n",
    "        rewards: reward obtained at each timestep.  Shape: (T,)\n",
    "        T: the number of frames, float\n",
    "        gae_lambda: hyperparameter, float\n",
    "        discount: discount factor, float\n",
    "\n",
    "        -----\n",
    "\n",
    "        returns:\n",
    "\n",
    "        advantages : tensor.float. Shape [T,]\n",
    "\n",
    "                    gae advantage term for timesteps 0 to T\n",
    "\n",
    "        \"\"\"\n",
    "        advantages = torch.zeros_like(values)\n",
    "        for i in reversed(range(T)):\n",
    "            next_value = values[i+1]\n",
    "            next_advantage = advantages[i+1]\n",
    "\n",
    "            delta = rewards[i] + self.args.discount * next_value  - values[i]\n",
    "            advantages[i] = delta + self.args.discount * self.args.gae_lambda * next_advantage\n",
    "        return advantages[:T]\n",
    "\n",
    "    def collect_experiences(self, env:gym.Env):\n",
    "        \"\"\"\n",
    "        Collects rollouts and computes advantages.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        exps : dict\n",
    "            Contains actions, rewards, advantages etc as attributes.\n",
    "            Each attribute, e.g. `exps['reward']` has a shape\n",
    "            (self.num_frames, ...).\n",
    "        logs : dict\n",
    "            Useful stats about the training process, including the average\n",
    "            reward, policy loss, value loss, etc.\n",
    "        \"\"\"\n",
    "        device = get_device()\n",
    "\n",
    "        MAX_FRAMES_PER_EP = 300\n",
    "        shape = (MAX_FRAMES_PER_EP, )\n",
    "\n",
    "        actions = torch.zeros(*shape, device=device, dtype=torch.int)\n",
    "        values = torch.zeros(*shape, device=device)\n",
    "        rewards = torch.zeros(*shape, device=device)\n",
    "        log_probs = torch.zeros(*shape, device=device)\n",
    "        obss = [None]*MAX_FRAMES_PER_EP\n",
    "\n",
    "        obs = env.reset()\n",
    "\n",
    "        total_return = 0\n",
    "\n",
    "        T = 0\n",
    "\n",
    "        while True:\n",
    "            # Do one agent-environment interaction\n",
    "            with torch.no_grad():\n",
    "                dist, value = self.model(obs)\n",
    "\n",
    "            dist: Categorical\n",
    "            action = dist.sample()[0]\n",
    "\n",
    "            obss[T] = obs\n",
    "            obs, reward, done, _, _ = env.step(action.item())\n",
    "\n",
    "            # Update experiences values\n",
    "            actions[T] = action\n",
    "            values[T] = value\n",
    "            rewards[T] = reward\n",
    "            log_probs[T] = dist.log_prob(action)\n",
    "\n",
    "            total_return += reward\n",
    "            T += 1\n",
    "\n",
    "            if done or T >= MAX_FRAMES_PER_EP-1:\n",
    "                break\n",
    "\n",
    "        success = (total_return > 0.5)\n",
    "\n",
    "        discounted_reward = self._compute_discounted_return(rewards[:T])\n",
    "        exps = dict(\n",
    "            obs = torch.tensor(np.array(obss[:T]), device=device),\n",
    "            action = actions[:T],\n",
    "            value  = values[:T],\n",
    "            reward = rewards[:T],\n",
    "            log_prob = log_probs[:T],\n",
    "            discounted_reward = discounted_reward,\n",
    "            T = T\n",
    "        )\n",
    "\n",
    "        logs = {\n",
    "            \"return_per_episode\": total_return,\n",
    "            \"num_frames\": T,\n",
    "            'success': success\n",
    "        }\n",
    "\n",
    "        return exps, logs\n",
    "\n",
    "    def _compute_policy_loss_ppo(self, dist:Categorical, factors, indices, old_logp, actions, advantages):\n",
    "        \"\"\"\n",
    "        Computes the policy loss for PPO.\n",
    "\n",
    "        obs: observeration to pass into acmodel. shape: (T,)\n",
    "        init_logp: log probabilities we get from the agent performing the action. shape: (T,)\n",
    "        old_logp: log probabilities from previous timestep. shape: (T,)\n",
    "        actions: action at this timestep. shape: (T,ImWidth,ImHeight,Channels)\n",
    "        advantages: the computed advantages. shape: (T,)\n",
    "\n",
    "        ---\n",
    "        returns\n",
    "\n",
    "        policy_loss : ppo policy loss as shown in line 6 of PPO alg. tensor.float. Shape (,1)\n",
    "        approx_kl: an appoximation of the kl_divergence. tensor.float. Shape (,1)\n",
    "        \"\"\"\n",
    "        policy_loss, approx_kl = 0, 0\n",
    "\n",
    "        coef = self.coef\n",
    "\n",
    "        entropy = dist.entropy()\n",
    "        logps = dist.log_prob(actions)\n",
    "        r_terms = torch.exp(logps - old_logp)\n",
    "        ppo_loss = torch.min(r_terms * advantages, torch.clamp(r_terms, 1 - self.args.clip_ratio, 1 + self.args.clip_ratio) * advantages)\n",
    "\n",
    "        policy_loss_tensor = factors * ppo_loss + coef * entropy\n",
    "\n",
    "        policy_loss = - torch.mean(policy_loss_tensor[indices])\n",
    "\n",
    "        # approx_kl = torch.sum(torch.exp(old_logp) * (old_logp - logps)) / torch.sum(torch.exp(old_logp))\n",
    "        approx_kl = torch.mean((old_logp - logps) ** 2) / 2\n",
    "\n",
    "        return policy_loss, approx_kl\n",
    "\n",
    "    def _compute_value_loss(self, values, returns):\n",
    "        value_loss = torch.mean((values - returns) ** 2)\n",
    "\n",
    "        return value_loss\n",
    "\n",
    "    def update_parameters(self, sb, update_v=True):\n",
    "        MAX_FRAMES_PER_EP = 300\n",
    "        T = sb['T']\n",
    "        with torch.no_grad():\n",
    "            dist, values = self.model(sb['obs'])\n",
    "        values = values.reshape(-1)\n",
    "        dist: Categorical\n",
    "        old_logp = dist.log_prob(sb['action'])\n",
    "        init_logp = sb['log_prob']\n",
    "\n",
    "        # add 0 to end of values until it has length MAX_FRAMES_PER_EP\n",
    "        values_extended = torch.cat([values, torch.zeros((MAX_FRAMES_PER_EP - len(values), ), device=get_device())], dim=0)\n",
    "        full_reward = torch.cat([sb['reward'], torch.zeros((MAX_FRAMES_PER_EP - len(sb['reward']), ), device=get_device())], dim=0)\n",
    "\n",
    "        if self.args.use_gae:\n",
    "            advantage = self._compute_advantage_gae(values_extended, full_reward, T)\n",
    "        else:\n",
    "            advantage = sb['discounted_reward'] - values.reshape(-1)\n",
    "\n",
    "        for i in range(self.args.train_ac_iters):\n",
    "            self.optim.zero_grad()\n",
    "            dist, values = self.model(sb['obs'])\n",
    "            values = values.reshape(-1)\n",
    "            # policy loss\n",
    "            factors = torch.exp(old_logp - init_logp)\n",
    "            indices = factors < self.args.importance_sampling_clip\n",
    "            fit = torch.mean(indices.to(torch.float32))\n",
    "\n",
    "            loss_pi, approx_kl = self._compute_policy_loss_ppo(dist, factors, indices, old_logp, sb['action'], advantage)\n",
    "            if update_v:\n",
    "                loss_v = self._compute_value_loss(values, sb['discounted_reward'])\n",
    "            else:\n",
    "                loss_v = 0.0\n",
    "\n",
    "            if i == 0:\n",
    "                policy_loss = loss_pi\n",
    "                value_loss = loss_v\n",
    "\n",
    "            loss = loss_v + loss_pi\n",
    "            if approx_kl > 1.5 * self.args.target_kl:\n",
    "                break\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            self.optim.step()\n",
    "\n",
    "        update_policy_loss = policy_loss.item()\n",
    "        update_value_loss = value_loss.item()\n",
    "\n",
    "        logs = {\n",
    "            \"policy_loss\": update_policy_loss,\n",
    "            \"value_loss\": update_value_loss,\n",
    "            \"fit\": fit.item()\n",
    "        }\n",
    "\n",
    "        return logs\n",
    "\n",
    "    def decrease_prob(self, sb, lr=0.1) -> None:\n",
    "        self.optim.zero_grad()\n",
    "\n",
    "        dist, _ = self.model(sb['obs'])\n",
    "        dist: Categorical\n",
    "        logps = dist.log_prob(sb['action'])\n",
    "\n",
    "        loss = lr * torch.mean(logps)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def __init__(self, ACModelClass, env, args:Config=None, seed=0):\n",
    "        \"\"\"\n",
    "        The PPO agent.\n",
    "        \"\"\"\n",
    "\n",
    "        self.env = env\n",
    "\n",
    "        set_random_seed(seed)\n",
    "        model = ACModelClass(use_critic=True).to(get_device())\n",
    "\n",
    "        if args is None:\n",
    "            args = Config()\n",
    "        self.machine = Machine(0.01, model, args)\n",
    "\n",
    "    def train(self, max_episodes:int=10000, nonstop:bool=False, max_frames=float('inf')) -> tuple[list[int], list[float]]:\n",
    "        \"\"\"\n",
    "        Train the PPO agent.\n",
    "\n",
    "        Returns:\n",
    "            num_frames, smooth_rs\n",
    "        \"\"\"\n",
    "\n",
    "        print(f'Start! Agent: PPO.')\n",
    "\n",
    "        is_solved = False\n",
    "\n",
    "        SMOOTH_REWARD_WINDOW = 50\n",
    "\n",
    "        rewards = [0]*SMOOTH_REWARD_WINDOW\n",
    "\n",
    "        total_smooth_rs = []\n",
    "        total_num_frames = []\n",
    "\n",
    "        num_frames = 0\n",
    "\n",
    "        pbar = tqdm(range(max_episodes))\n",
    "        for update in pbar:\n",
    "\n",
    "            exps, logs1 = self.machine.collect_experiences(self.env)\n",
    "\n",
    "            logs2 = self.machine.update_parameters(exps)\n",
    "\n",
    "            logs = {**logs1, **logs2}\n",
    "\n",
    "            total_num_frames.append(num_frames)\n",
    "            num_frames += logs[\"num_frames\"]\n",
    "\n",
    "            rewards.append(logs[\"return_per_episode\"])\n",
    "\n",
    "            smooth_reward = np.mean(rewards[-SMOOTH_REWARD_WINDOW:])\n",
    "\n",
    "            total_smooth_rs.append(smooth_reward)\n",
    "\n",
    "            data = {'num_frames':num_frames, 'smooth_reward':smooth_reward,\n",
    "                'reward':logs[\"return_per_episode\"], 'policy_loss':logs[\"policy_loss\"], 'value_loss': logs['value_loss'], 'episode':update}\n",
    "\n",
    "            pbar.set_postfix(data)\n",
    "\n",
    "            if not nonstop and smooth_reward >= self.machine.args.score_threshold:\n",
    "                is_solved = True\n",
    "                break\n",
    "            if num_frames >= max_frames:\n",
    "                break\n",
    "\n",
    "        if not nonstop and is_solved:\n",
    "            print('Solved!')\n",
    "\n",
    "        return total_num_frames, total_smooth_rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork(nn.Module):\n",
    "    def __init__(self, action_dim):\n",
    "        \"\"\"\n",
    "        Initializes the DQNetwork with a convolutional neural network architecture.\n",
    "\n",
    "        Parameters:\n",
    "        - action_dim (int): The number of possible actions, determining the output size of the network.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (3, 3)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, action_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, ob):\n",
    "        \"\"\"\n",
    "        Processes an observation through the network to predict Q values for each action.\n",
    "\n",
    "        Parameters:\n",
    "        - ob (torch.Tensor): The input observation image of shape [batch_size, height, width, channels].\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: The predicted Q values for each action, of shape [batch_size, action_dim].\n",
    "        \"\"\"\n",
    "        #### TODO (5pts): get the Q values for each action given the input\n",
    "        #### the input shape is: [batch_size, H, W, 3]\n",
    "        #### output shape should be: [batch_size, # of actions]\n",
    "        ob = ob.permute(0, 3, 1, 2)\n",
    "        bs = ob.size(0)\n",
    "        out = self.conv_net(ob)\n",
    "        out = out.view(bs, -1)\n",
    "        out = self.fcs(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# create a replay buffer\n",
    "class CyclicBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = []\n",
    "        self.capacity = capacity\n",
    "        self.cur_pos = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.buffer[item]\n",
    "\n",
    "    def append(self, data):\n",
    "        \"\"\"\n",
    "        Adds a new piece of data to the buffer.\n",
    "\n",
    "        Parameters:\n",
    "        - data: The data to be added to the buffer.\n",
    "        \"\"\"\n",
    "        #### TODO (10pts): add data to the buffer\n",
    "        #### if the buffer is not full yet, you can simply append the data to the buffer\n",
    "        #### otherwise, you need to replace the oldest data with the current data (FIFO)\n",
    "        #### Hint: you may find self.cur_pos useful, it can be used as a position index\n",
    "        #### to keep track of where to add data\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(data)\n",
    "            self.cur_pos = (self.cur_pos + 1) % self.capacity\n",
    "        else:\n",
    "            self.buffer[self.cur_pos] = data\n",
    "            self.cur_pos = (self.cur_pos + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Randomly selects a batch of data from the buffer. The size of the batch is the minimum of the requested\n",
    "        batch size and the current size of the buffer. If the requested batch size equals the buffer size, all\n",
    "        data in the buffer is returned.\n",
    "\n",
    "        Parameters:\n",
    "        - batch_size (int): The size of the batch to sample.\n",
    "\n",
    "        Returns:\n",
    "        - list: A list containing the sampled batch of data.\n",
    "        \"\"\"\n",
    "        #### TODO (10pts): sample a batch from the buffer\n",
    "        bs = min(batch_size, len(self.buffer))\n",
    "        return random.sample(self.buffer, bs)\n",
    "\n",
    "    def get_all(self):\n",
    "        \"\"\"\n",
    "        Retrieves all data stored in the buffer.\n",
    "\n",
    "        Returns:\n",
    "        - list: A deepcopy of all data currently stored in the buffer.\n",
    "        \"\"\"\n",
    "        return deepcopy(self.buffer)\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"\n",
    "        Removes all data from the buffer, effectively resetting its state.\n",
    "        \"\"\"\n",
    "        self.buffer.clear()\n",
    "        self.cur_pos = 0\n",
    "\n",
    "@dataclass\n",
    "class DQNAgent:\n",
    "    env: gym.Env\n",
    "    learning_rate: float\n",
    "    gamma: float\n",
    "    memory_size: int # We use memory/buffer interchangeably\n",
    "    initial_epsilon: float\n",
    "    min_epsilon: float\n",
    "    max_epsilon_decay_steps: int\n",
    "    warmup_steps: int\n",
    "    batch_size: int\n",
    "    target_update_freq: int\n",
    "    enable_double_q: bool = False\n",
    "    disable_target_net: bool = False\n",
    "    device: str = None\n",
    "    tau: float = 0.0005 # changed from 0.005 to 0.0005\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the agent to its initial state.\n",
    "        \"\"\"\n",
    "        if self.device is None:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        #### TODO: create a Deep Q network Agent.\n",
    "        #### For our purposes include the following:\n",
    "        #### -a replay buffer with capacity=self.memory_size. Memory = Buffer\n",
    "        self.memory = CyclicBuffer(self.memory_size)\n",
    "        #### -an Adam optimizer with lr=self.learning_rate,\n",
    "        self.qnet = DQNetwork(action_dim=7).to(self.device)\n",
    "        self.optim = torch.optim.Adam(self.qnet.parameters(), lr=self.learning_rate)\n",
    "        #### -SmoothL1 loss instance,\n",
    "        self.loss = nn.SmoothL1Loss()\n",
    "        ####  -a deep Q network\n",
    "        ####  -A deep Q TARGET network (Make sure to set to eval mode)\n",
    "        self.target_qnet = DQNetwork(action_dim=7).to(self.device)\n",
    "        self.target_qnet.eval()\n",
    "        #### -Make sure the networks are on the correct device!!! use [tensor].to(self.device)\n",
    "\n",
    "        ####\n",
    "        self.epsilon = self.initial_epsilon\n",
    "        self.ep_reduction = (self.epsilon - self.min_epsilon) / float(self.max_epsilon_decay_steps)\n",
    "        if self.disable_target_net:\n",
    "            #### TODO: set the target_update_freq to be proper value so that the target Q network will always be same as the Q network\n",
    "            #### You don't need to fill in this value until Q4.3\n",
    "            self.target_update_freq = 1\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_action(self, ob, greedy_only=False):\n",
    "        \"\"\"\n",
    "        Selects an action based on the current state observation using an epsilon-greedy policy.\n",
    "\n",
    "        Parameters:\n",
    "        - ob (numpy.ndarray): The current state observation.\n",
    "        - greedy_only (bool): If True, the method always selects the action with the highest Q value. If False, it\n",
    "        selects a random action with probability epsilon.\n",
    "\n",
    "        Returns:\n",
    "        - int: The selected action.\n",
    "        \"\"\"\n",
    "        ob = ob[np.newaxis, :]\n",
    "        ob = torch.from_numpy(ob).float().to(self.device)\n",
    "        q_val = self.qnet(ob)\n",
    "        action = self.epsilon_greedy_policy(q_val, greedy_only=greedy_only)\n",
    "        return action\n",
    "\n",
    "    def epsilon_greedy_policy(self, q_values, greedy_only=False):\n",
    "        \"\"\"\n",
    "        Implements an epsilon-greedy policy for action selection.\n",
    "\n",
    "        Parameters:\n",
    "        - q_values (torch.Tensor): The Q values for all actions in the current state.\n",
    "        - greedy_only (bool): If True, ignores epsilon and selects the action with the highest Q value.\n",
    "\n",
    "        Returns:\n",
    "        - int: The index of the selected action.\n",
    "        \"\"\"\n",
    "        #### TODO: epsilon greedy exploration\n",
    "        #### we have an extra flag `greedy_only` here,\n",
    "        #### if greedy_only is True, then we need to return the action that\n",
    "        #### has the maximum Q values.\n",
    "        #### if greedy_only is False, we do epsilon greedy.\n",
    "        mode = 'random'\n",
    "        if greedy_only:\n",
    "            mode = 'greedy'\n",
    "        else:\n",
    "            if random.random() < self.epsilon:\n",
    "                mode = 'random'\n",
    "            else:\n",
    "                mode = 'greedy'\n",
    "\n",
    "        if mode == 'random':\n",
    "            action = np.random.randint(0, 7)\n",
    "        elif mode == 'greedy':\n",
    "            action = torch.argmax(q_values).item()\n",
    "        else:\n",
    "            raise ValueError('Unknown mode')\n",
    "\n",
    "        return action\n",
    "\n",
    "    def add_to_memory(self, ob, next_ob, action, reward, done):\n",
    "        \"\"\"\n",
    "        Adds an experience tuple to the replay buffer.\n",
    "\n",
    "        Parameters:\n",
    "        - ob: The current state observation.\n",
    "        - next_ob: The next state observation after taking the action.\n",
    "        - action: The action taken in the current state.\n",
    "        - reward: The reward received after taking the action.\n",
    "        - done: A boolean indicating whether the episode has ended.\n",
    "        \"\"\"\n",
    "        #### TODO: add data to the replay buffer. Avoid np.arrays.\n",
    "        data = (ob, next_ob, action, reward, done)\n",
    "        self.memory.append(data)\n",
    "\n",
    "    def update_Q(self):\n",
    "        \"\"\"\n",
    "        Performs a single update step of the Q-network based on a batch of experiences from the replay buffer.\n",
    "\n",
    "        Returns:\n",
    "        - float: The loss value of the update step.\n",
    "        \"\"\"\n",
    "        # we only start updating the Q network if there are enough samples in the replay buffer\n",
    "        if len(self.memory) < self.warmup_steps:\n",
    "            return 0\n",
    "\n",
    "        #### TODO: sample data from the replay buffer, and put them on the correct device (use [tensor].to(self.device))\n",
    "        #### you need to make sure the variables are in the right tensor shape.\n",
    "        data = self.memory.sample(self.batch_size)\n",
    "\n",
    "\n",
    "        #### TODO: update Q function with Bellman backup. Torch.gather() may prove useful for this section\n",
    "        ##### get Q(s_t, a_t)\n",
    "        obs, next_obs, actions, rewards, dones = zip(*data)\n",
    "        obs = np.array(obs)\n",
    "        next_obs = np.array(next_obs)\n",
    "        actions = np.array(actions)\n",
    "        rewards = np.array(rewards)\n",
    "        dones = np.array(dones)\n",
    "        obs = torch.tensor(obs, device=self.device, dtype=torch.float32)\n",
    "        next_obs = torch.tensor(next_obs, device=self.device, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, device=self.device)\n",
    "        rewards = torch.tensor(rewards, device=self.device, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, device=self.device, dtype=torch.int32)\n",
    "\n",
    "        q_values = self.qnet(obs)\n",
    "        # then select the index from q_values according to actions\n",
    "        q_values = q_values.gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "\n",
    "        ##### get maxQ(s_{t+1}, a_{t+1})\n",
    "        ##### you will need to implement both DQN and double DQN here\n",
    "        ##### i.e., you need to check `if self.enable_double_q`\n",
    "        ##### remember to not propogate gradient when working with target\n",
    "        if self.enable_double_q:\n",
    "            with torch.no_grad():\n",
    "                out = self.qnet(next_obs)\n",
    "                max_q_indices = torch.max(out, dim=1)[1]\n",
    "\n",
    "                out = self.target_qnet(next_obs)\n",
    "                max_q_values = out.gather(1, max_q_indices.unsqueeze(1)).squeeze(1)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                out = self.target_qnet(next_obs)\n",
    "                max_q_values = torch.max(out, dim=1)[0]\n",
    "\n",
    "\n",
    "        ##### get the target Q value from the bellman equation\n",
    "        target_q_values = rewards + (1 - dones) * self.gamma * max_q_values\n",
    "\n",
    "        ##### update the Q network\n",
    "        self.optim.zero_grad()\n",
    "        loss = self.loss(target_q_values, q_values)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        \"\"\"\n",
    "        Reduces epsilon linearly over time until it reaches min_epsilon, ensuring that the exploration rate decreases\n",
    "        as the agent learns more about the environment.\n",
    "        \"\"\"\n",
    "        #### TODO: linearly decay epsilon\n",
    "        #### reduce epsilon value by ep_reduction every time the function is called,\n",
    "        #### make sure epsilon is not smaller than self.min_epsilon\n",
    "        self.epsilon = max(self.epsilon - self.ep_reduction, self.min_epsilon)\n",
    "\n",
    "    def set_epsilon(self, eps) -> None:\n",
    "        \"\"\"\n",
    "        Sets the epsilon value to a specified value.\n",
    "\n",
    "        Parameters:\n",
    "        - eps (float): The new epsilon value.\n",
    "        \"\"\"\n",
    "        self.epsilon = eps\n",
    "\n",
    "    def update_target_qnet(self, step, soft=True):\n",
    "        \"\"\"\n",
    "        Updates the target Q-network.\n",
    "\n",
    "        Parameters:\n",
    "        - step (int): The current step number, used to determine when to perform hard updates.\n",
    "        - soft (bool): If True, performs a soft update; otherwise, performs a hard update.\n",
    "        \"\"\"\n",
    "        if not soft:\n",
    "            if step % self.target_update_freq == 0:\n",
    "                #### TODO: update the target Q function in a \"hard\" way\n",
    "                #### copy the parameter values in self.qnet into self.target_qnet\n",
    "                ### use .copy_() to avoid pointer issues\n",
    "                state_dict = self.qnet.state_dict()\n",
    "                for key, v in state_dict.items():\n",
    "                    self.target_qnet.state_dict()[key].copy_(v)\n",
    "                self.target_qnet.eval()\n",
    "        else:\n",
    "            #### TODO: soft update on taget Q network.\n",
    "            #### similar to polyak averaging, we update the target Q network slowly\n",
    "            #### $\\theta_Qtgt = \\tau*\\theta_Qtgt + (1-\\tau)*\\theta_Q\n",
    "            ###  use .copy_() to avoid pointer issues\n",
    "            state_dict = self.qnet.state_dict()\n",
    "            for key, v in state_dict.items():\n",
    "                self.target_qnet.state_dict()[key].copy_((1 - self.tau) * self.target_qnet.state_dict()[key] + self.tau * v)\n",
    "            self.target_qnet.eval()\n",
    "\n",
    "# you don't need to modify the following code.\n",
    "@dataclass\n",
    "class DQNEngine:\n",
    "    env: gym.Env\n",
    "    agent: DQNAgent\n",
    "    max_steps: int\n",
    "    show_progress: bool = False\n",
    "    show_video: bool = False\n",
    "\n",
    "    def test(self, env=None, render=False):\n",
    "        \"\"\"\n",
    "        Evaluates the agent's performance in the given environment.\n",
    "\n",
    "        Parameters:\n",
    "        - env (gym.Env, optional): The environment to test the agent in. If None, uses the engine's environment.\n",
    "        - render (bool): Whether to render the environment at each step.\n",
    "\n",
    "        Returns:\n",
    "        - float: The total reward accumulated over the episode.\n",
    "        \"\"\"\n",
    "        env = self.env if env is None else env\n",
    "        ob = env.reset()\n",
    "        ret = 0\n",
    "        for i in range(300):\n",
    "            if render:\n",
    "                env.render()\n",
    "            action = self.agent.get_action(ob, greedy_only=True)\n",
    "            next_ob, reward, done, truncated, info = env.step(action)\n",
    "            ret += reward\n",
    "            ob = next_ob\n",
    "            if done:\n",
    "                break\n",
    "        return ret\n",
    "\n",
    "    def run(self, n_runs=1):\n",
    "        \"\"\"\n",
    "        Executes multiple runs of the agent in the environment, training the agent in each run.\n",
    "\n",
    "        Parameters:\n",
    "        - n_runs (int): The number of separate runs to execute.\n",
    "\n",
    "        Returns:\n",
    "        - list: A list of pandas DataFrame logs for each run, containing columns for the cumulative reward ('return'),\n",
    "                the step count ('steps'), the episode number ('episode'), and the initial epsilon value ('epsilon').\n",
    "        \"\"\"\n",
    "        eps = 0.999\n",
    "\n",
    "        rewards = []\n",
    "        log = []\n",
    "\n",
    "        for i in tqdm(range(n_runs), desc='Runs'):\n",
    "            ep_rewards = []\n",
    "            ep_steps = []\n",
    "            test_rets = []\n",
    "            self.agent.reset()\n",
    "            # we plot the smoothed return values\n",
    "            smooth_ep_return = deque(maxlen=10)\n",
    "            ob = self.env.reset()\n",
    "            ret = 0\n",
    "            num_ep = 0\n",
    "            for t in tqdm(range(self.max_steps), desc='Step'):\n",
    "                if len(self.agent.memory) < self.agent.warmup_steps:\n",
    "                    action = self.env.action_space.sample()\n",
    "                else:\n",
    "                    action = self.agent.get_action(ob)\n",
    "                next_ob, reward, done, truncated, info = self.env.step(action)\n",
    "                true_done = done and not info.get('TimeLimit.truncated', False)\n",
    "                self.agent.add_to_memory(ob, next_ob, action, reward, true_done)\n",
    "                self.agent.update_Q()\n",
    "                ret += reward\n",
    "                ob = next_ob\n",
    "                if done or truncated:\n",
    "                    ob = self.env.reset()\n",
    "                    smooth_ep_return.append(ret)\n",
    "                    ep_rewards.append(np.mean(smooth_ep_return))\n",
    "                    ep_steps.append(t)\n",
    "                    ret = 0\n",
    "                    num_ep += 1\n",
    "                    if self.show_progress:\n",
    "                        print(f'Step:{t}  epsilon:{self.agent.epsilon}  '\n",
    "                            f'Smoothed Training Return:{np.mean(smooth_ep_return)}')\n",
    "                    if num_ep % 10 == 0:\n",
    "                        test_ret = self.test()\n",
    "                        test_rets.append(test_ret)\n",
    "                        if self.show_progress:\n",
    "                            print('==========================')\n",
    "                            print(f'Step:{t} Testing Return: {test_ret}')\n",
    "\n",
    "                self.agent.decay_epsilon()\n",
    "                self.agent.update_target_qnet(t, soft=not self.agent.disable_target_net)\n",
    "\n",
    "            rewards.append(ep_rewards)\n",
    "            run_log = pd.DataFrame({'return': ep_rewards,\n",
    "                                    'steps': ep_steps,\n",
    "                                    'episode': np.arange(len(ep_rewards)),\n",
    "                                    'epsilon': self.agent.initial_epsilon})\n",
    "            log.append(run_log)\n",
    "\n",
    "            log_alt = [ep_steps[9::10], test_rets]\n",
    "        return log, log_alt\n",
    "\n",
    "def dqn_sweep(agents, labels, n_runs=1, max_steps=100000, show_progress=False):\n",
    "    \"\"\"\n",
    "    Performs a sweep over different DQN agents to compare their performance.\n",
    "    This function takes a list of DQN agents and their labels, then runs each agent for a specified number of runs and\n",
    "    steps, tracking their performance. Useful for comparing the effects of different hyperparameters or architectures\n",
    "    across multiple agents.\n",
    "\n",
    "    Parameters:\n",
    "    - agents (list): A list of DQNAgent instances to be evaluated.\n",
    "    - labels (list): A list of strings representing labels for each agent, used in the logs to identify the agents.\n",
    "    - n_runs (int): The number of runs to execute for each agent.\n",
    "    - max_steps (int): The maximum number of steps to execute in each run.\n",
    "    - show_progress (bool): Whether to display progress bars during execution.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A concatenated DataFrame containing the logs of all runs for all agents, with an additional\n",
    "                         'Agent' column indicating the label of the agent for each log entry.\n",
    "    \"\"\"\n",
    "    logs = dict()\n",
    "    for idx, agent in enumerate(tqdm(agents)):\n",
    "        engine = DQNEngine(env=agent.env, agent=agent,\n",
    "                           max_steps=max_steps, show_progress=show_progress)\n",
    "        ep_log, log_alt = engine.run(n_runs)\n",
    "        ep_log = pd.concat(ep_log, ignore_index=True)\n",
    "        ep_log['Agent'] = labels[idx]\n",
    "        logs[f'{idx}'] = ep_log\n",
    "    logs = pd.concat(logs, ignore_index=True)\n",
    "    return logs, log_alt\n",
    "\n",
    "def get_default_config():\n",
    "    config = dict(\n",
    "        learning_rate=0.00025,\n",
    "        gamma=0.99,\n",
    "        memory_size=200000,\n",
    "        initial_epsilon=1.0,\n",
    "        min_epsilon=0.1,\n",
    "        max_epsilon_decay_steps=150000,\n",
    "        warmup_steps=500,\n",
    "        target_update_freq=2000,\n",
    "        batch_size=32,\n",
    "        device=None,\n",
    "        disable_target_net=False,\n",
    "        enable_double_q=True\n",
    "    )\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRR:\n",
    "    def __init__(self, ACModelClass, env, args:Config=None, seed=0):\n",
    "        \"\"\"\n",
    "        The RRR agent.\n",
    "        \"\"\"\n",
    "\n",
    "        self.env = env\n",
    "\n",
    "        set_random_seed(seed)\n",
    "        m1 = ACModelClass(use_critic=True).to(get_device())\n",
    "\n",
    "        if args is None:\n",
    "            args = Config()\n",
    "\n",
    "        self.exploiter = Machine(0.01, m1, args)\n",
    "\n",
    "        m2 = ACModelClass(use_critic=False).to(get_device())\n",
    "        m3 = ACModelClass(use_critic=False).to(get_device())\n",
    "        m4 = ACModelClass(use_critic=False).to(get_device())\n",
    "\n",
    "        self.explorer_random = Machine(0.03, m2, args)\n",
    "        self.explorer_thirsty = Machine(0.02, m3, args)\n",
    "        self.explorer_thirsty.copy_machine(self.exploiter)\n",
    "\n",
    "        self.temp_machine = Machine(0.01, m3, args)\n",
    "        self.explorer_bengbuzhu = Machine(0.5, m4, args)\n",
    "\n",
    "    def _replay(self, machine:Machine, buffer:list, cutoff:float) -> float:\n",
    "        \"\"\"\n",
    "        Replay random sample from buffer on machine.\n",
    "\n",
    "        Args:\n",
    "            machine: Machine to replay on\n",
    "            buffer: list of experiences\n",
    "            cutoff: if fit < cutoff, delete sb from buffer\n",
    "\n",
    "        Returns:\n",
    "            fit\n",
    "        \"\"\"\n",
    "\n",
    "        idx = np.random.randint(len(buffer))\n",
    "        sb = buffer[idx]\n",
    "        logs_replay = machine.update_parameters(sb)\n",
    "        fit = logs_replay['fit']\n",
    "        if fit < cutoff:\n",
    "            # delete sb from buffer\n",
    "            buffer.pop(idx)\n",
    "\n",
    "        return fit\n",
    "\n",
    "    def _add_sb_to_buffer(self, exps, buffer:list, capacity:int) -> None:\n",
    "        buffer.append(exps)\n",
    "        if len(buffer) > capacity:\n",
    "            buffer.pop(0)\n",
    "\n",
    "\n",
    "    def train(self, max_episodes:int=10000, nonstop:bool=False, max_frames=float('inf')) -> tuple[list[int], list[float], list[float]]:\n",
    "        \"\"\"\n",
    "        Train the agent.\n",
    "\n",
    "        Returns:\n",
    "            num_frames, smooth_rs, fits\n",
    "        \"\"\"\n",
    "\n",
    "        print('Start! Agent: RRR.')\n",
    "        RANDOM_MODE = 0\n",
    "        EXPLORE_MODE = 1\n",
    "        EXPLOIT_MODE = 2\n",
    "        mode = RANDOM_MODE\n",
    "\n",
    "        is_solved = False\n",
    "\n",
    "        SMOOTH_REWARD_WINDOW = 50\n",
    "\n",
    "        rewards = [0]*SMOOTH_REWARD_WINDOW\n",
    "\n",
    "        total_smooth_rs = []\n",
    "        total_num_frames = []\n",
    "        larger_buffer_r = []\n",
    "        buffer_r = []\n",
    "        buffer_no_r = []\n",
    "        fits = []\n",
    "\n",
    "        num_frames = 0\n",
    "\n",
    "        pbar = tqdm(range(max_episodes))\n",
    "        for update in pbar:\n",
    "            total_num_frames.append(num_frames)\n",
    "\n",
    "            if mode == RANDOM_MODE:\n",
    "                exps, logs1 = self.explorer_bengbuzhu.collect_experiences(self.env)\n",
    "                self.explorer_bengbuzhu.update_parameters(exps)\n",
    "                logs2 = self.exploiter.update_parameters(exps)\n",
    "\n",
    "            elif mode == EXPLORE_MODE:\n",
    "                if np.random.rand() < 0.5:\n",
    "                    m = self.explorer_random\n",
    "                else:\n",
    "                    m = self.explorer_thirsty\n",
    "\n",
    "                exps, logs1 = m.collect_experiences(self.env)\n",
    "\n",
    "                m.update_parameters(exps)\n",
    "                logs2 = self.exploiter.update_parameters(exps)\n",
    "\n",
    "                if len(larger_buffer_r) >= 1:\n",
    "                    self._replay(self.explorer_thirsty, larger_buffer_r, cutoff=0.0)\n",
    "\n",
    "            elif mode == EXPLOIT_MODE:\n",
    "                exps, logs1 = self.exploiter.collect_experiences(self.env)\n",
    "\n",
    "                logs2 = self.exploiter.update_parameters(exps)\n",
    "\n",
    "                assert len(buffer_r) > 0, f'buffer_r should not be empty.'\n",
    "\n",
    "                cutoff = self.exploiter.args.bad_fit_threshold + self.exploiter.args.bad_fit_increment * (len(buffer_r) - 1)\n",
    "\n",
    "                if not logs1['success'] and total_smooth_rs[-1] <= 0.5:\n",
    "                    fit = self._replay(self.exploiter, buffer_r, cutoff)\n",
    "                    fits.append(fit)\n",
    "\n",
    "                if len(buffer_r) == 0:\n",
    "                    print(f'At episode {update}, we lost all data in replay buffer...')\n",
    "                    mode = EXPLORE_MODE\n",
    "                    self.explorer_thirsty.copy_machine(self.exploiter)\n",
    "                    self.explorer_random.copy_machine(self.temp_machine)\n",
    "                    self.temp_machine.copy_machine(self.exploiter)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f'Invalid mode: {mode}')\n",
    "\n",
    "            logs = {**logs1, **logs2}\n",
    "\n",
    "            num_frames += logs[\"num_frames\"]\n",
    "\n",
    "            rewards.append(logs[\"return_per_episode\"])\n",
    "\n",
    "            if logs['success']:\n",
    "                if mode == RANDOM_MODE:\n",
    "                    print(f'First successful data collected at episode {update}! We will be accelerating.')\n",
    "                elif mode == EXPLORE_MODE:\n",
    "                    if m is self.explorer_random:\n",
    "                        info_print = 'random explorer'\n",
    "                    elif m is self.explorer_thirsty:\n",
    "                        info_print = 'thirsty explorer'\n",
    "                    else:\n",
    "                        raise ValueError(f'Invalid explorer: {m}')\n",
    "\n",
    "                    print(f'At episode {update}, {info_print} collected a successful data.')\n",
    "                elif mode == EXPLOIT_MODE:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise ValueError(f'Invalid mode: {mode}')\n",
    "                self._add_sb_to_buffer(exps, buffer_r, self.exploiter.args.replay_buffer_capacity)\n",
    "                self._add_sb_to_buffer(exps, larger_buffer_r, self.exploiter.args.large_buffer_capacity)\n",
    "                mode = EXPLOIT_MODE\n",
    "            else:\n",
    "                self._add_sb_to_buffer(exps, buffer_no_r, self.exploiter.args.replay_buffer_capacity)\n",
    "\n",
    "            smooth_reward = np.mean(rewards[-SMOOTH_REWARD_WINDOW:])\n",
    "\n",
    "            total_smooth_rs.append(smooth_reward)\n",
    "\n",
    "            data = {'num_frames':num_frames, 'smooth_reward':smooth_reward,\n",
    "                'reward':logs[\"return_per_episode\"], 'episode':update}\n",
    "\n",
    "            pbar.set_postfix(data)\n",
    "\n",
    "            if not nonstop and smooth_reward >= self.exploiter.args.score_threshold:\n",
    "                    is_solved = True\n",
    "                    break\n",
    "            if num_frames >= max_frames:\n",
    "                break\n",
    "\n",
    "        if is_solved:\n",
    "            print('Solved!')\n",
    "\n",
    "        return total_num_frames, total_smooth_rs, fits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACModel(nn.Module):\n",
    "    def __init__(self, use_critic=False):\n",
    "        \"\"\"\n",
    "        Represents an Actor Crictic model that takes a 2d, multi-channeled\n",
    "        image as input.\n",
    "\n",
    "        Parameters\n",
    "        ----\n",
    "        num_actions : int\n",
    "\n",
    "                      The action space of the environment.\n",
    "                      The action space for DoorKey5x5 is 7-dimensional:\n",
    "                      0: turn left,\n",
    "                      1: turn right,\n",
    "                      2: forward,\n",
    "                      3: pickup an object,\n",
    "                      4: drop an object,\n",
    "                      5: activate an object,\n",
    "                      6: done completing task\n",
    "\n",
    "        use_critics : bool\n",
    "\n",
    "                      Critic network will be used in forward pass if flag is set\n",
    "                      to true.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.use_critic = use_critic\n",
    "\n",
    "        # Define actor's model\n",
    "        self.image_conv_actor = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 7)\n",
    "        )\n",
    "\n",
    "        # Define critic's model\n",
    "        if self.use_critic:\n",
    "            self.image_conv_critic = nn.Sequential(\n",
    "                nn.Conv2d(3, 16, (2, 2)),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d((2, 2)),\n",
    "                nn.Conv2d(16, 32, (2, 2)),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(32, 64, (2, 2)),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            self.critic = nn.Sequential(\n",
    "                nn.Linear(64, 64),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(64, 1)\n",
    "            )\n",
    "\n",
    "        # Initialize parameters correctly\n",
    "        self.apply(init_params)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the actor-critic network\n",
    "\n",
    "        Parameters\n",
    "        ----\n",
    "        obs : int tensor. Shape [Batch size, ImWidth, ImHeight, Channels]\n",
    "\n",
    "              input to the network.\n",
    "        ----\n",
    "\n",
    "        returns:\n",
    "\n",
    "        dist : torch.distribution\n",
    "            The distribution of actions from policy. A Categorical distribution\n",
    "            for discreet action spaces.\n",
    "        value : torch.Tensor (Batch size, 1)\n",
    "            value output by critic network\n",
    "        \"\"\"\n",
    "        device = get_device()\n",
    "        obs = torch.tensor(obs).float() # convert to float tensor\n",
    "        obs = obs.to(device)\n",
    "        if len(obs.shape) == 3:\n",
    "            obs = obs.unsqueeze(0) # add batch dimension if not already there\n",
    "\n",
    "        conv_in = obs.transpose(1, 3).transpose(2, 3) # reshape into [b, c, h, w]\n",
    "\n",
    "        dist, value = None, None\n",
    "\n",
    "        x = self.image_conv_actor(conv_in)\n",
    "        embedding = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        x = self.actor(embedding)\n",
    "        dist = Categorical(logits=F.log_softmax(x, dim=1))\n",
    "\n",
    "        if self.use_critic:\n",
    "            y = self.image_conv_critic(conv_in)\n",
    "            embedding = y.reshape(y.shape[0], -1)\n",
    "\n",
    "            value = self.critic(embedding).squeeze(1)\n",
    "        else:\n",
    "            value = torch.zeros((x.shape[0], 1), device=x.device)\n",
    "\n",
    "        return dist, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = 6\n",
    "seed = 62\n",
    "\n",
    "env = get_door_key_env(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3888546a0634b32832d14578024cd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb524e46b60f40b082a18d5e08e5e065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e7ca289d764efbbb3f0201461bf5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Step:   0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start! Agent: PPO.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac43991d823a4daaa0118e1808391aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/sdw3gh1d1lj552x1k2x500mw0000gn/T/ipykernel_8806/2006739843.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  obs = torch.tensor(obs).float() # convert to float tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start! Agent: RRR.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0532115a21e4d76b8ee0177c48888de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First successful data collected at episode 6! We will be accelerating.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_frames = 150000\n",
    "max_episodes = 4000000\n",
    "nonstop = True\n",
    "set_random_seed(seed)\n",
    "\n",
    "config = get_default_config()\n",
    "config['batch_size'] = 128\n",
    "config['max_epsilon_decay_steps'] = int(1.5 * max_frames)\n",
    "config['memory_size'] = int(2 * max_frames)\n",
    "config['warmup_steps'] = 500\n",
    "agent = DQNAgent(env=env, **config)\n",
    "\n",
    "dqn_logs, log_alt = dqn_sweep([agent], ['DDQN'], max_steps=max_frames)\n",
    "\n",
    "num_frames_DDQN = list(log_alt[0])\n",
    "rewards_DDQN = list(log_alt[1])\n",
    "length = min(len(num_frames_DDQN), len(rewards_DDQN))\n",
    "num_frames_DDQN = num_frames_DDQN[:length]\n",
    "rewards_DDQN = rewards_DDQN[:length]\n",
    "# first prepend 49 zeros to the rewards to make the plot start at 0\n",
    "rewards_DDQN = [0] * 49 + rewards_DDQN\n",
    "# smooth the rewards by averaging on 50 of them\n",
    "rewards_DDQN = [sum(rewards_DDQN[i:i+50])/50 for i in range(len(rewards_DDQN)-49)]\n",
    "\n",
    "agent_PPO = PPO(ACModel, env=env, args=Config(), seed=seed)\n",
    "num_frames_1, smooth_rs_1 = agent_PPO.train(max_episodes, nonstop=nonstop, max_frames=max_frames)\n",
    "agent_RRR_2 = RRR(ACModel, env=env, args=Config(bad_fit_threshold=0.77, importance_sampling_clip=2.0), seed=seed)\n",
    "num_frames_2, smooth_rs_2, fits_2 = agent_RRR_2.train(max_episodes, nonstop=nonstop, max_frames=max_frames)\n",
    "\n",
    "plt.plot(num_frames_1, smooth_rs_1, label='PPO')\n",
    "plt.plot(num_frames_DDQN, rewards_DDQN, label='DDQN')\n",
    "plt.plot(num_frames_2, smooth_rs_2, label='RRR')\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Average reward (smoothed)')\n",
    "plt.title(f'DoorKeyEnv, size = {size}, seed = {seed}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
